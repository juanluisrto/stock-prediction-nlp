{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALBERT + InceptionNet\n",
    "In this notebook I try to train ALBERT (a reduced version of BERT and classify the outputs with Inception NEt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "#import bert\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "df_bitcoin = pd.read_csv(\"csv/articles_Bitcoin-Cryptocurrency_start=2019-01-01_end=2020-12-31.csv\", index_col = 0)\n",
    "df_tesla = pd.read_csv(\"csv/articles_Tesla-Elon_Musk_start=2019-01-01_end=2020-12-31.csv\", index_col = 0)\n",
    "df = df_bitcoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "start = \"2019-01-01\"\n",
    "end   = \"2020-03-20\"\n",
    "\n",
    "stocks = [\"TSLA\"]\n",
    "keywords = {\"TSLA\": [\"Tesla\", \"Elon Musk\"]}\n",
    "stocks = [\"BTC-USD\"]\n",
    "keywords = {\"BTC-USD\" : [\"Bitcoin\", \"Cryptocurrency\"] }\n",
    "\n",
    "df_financial = yf.download(stocks, \n",
    "                     #period = \"1Y\",\n",
    "                      start= start, \n",
    "                      end= end, \n",
    "                      progress=False)\n",
    "prices = df_financial[\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.DataFrame(data = prices, index = pd.date_range(start,end)).fillna(method = \"bfill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ~Titles and descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles and descriptions\n",
    "titles = df.title\n",
    "titles.index = df[\"date_google\"]\n",
    "descriptions = df.description\n",
    "descriptions.index = df[\"date_google\"]\n",
    "text = pd.concat([titles,descriptions]).sort_index().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whole text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_text\n",
    "text = df.maintext #pd.DataFrame(df.maintext.values, index = df[\"date_google\"]).dropna()\n",
    "text.index = df[\"date_google\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "\n",
    "split_sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_sentences = text.apply(split_sentence_tokenizer.tokenize)\n",
    "split_sentences = split_sentences.groupby(split_sentences.index).sum()\n",
    "split_sentences = pd.DataFrame(split_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maintext</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_google</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>[Cryptocurrency exchange HitBTC has frozen its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>[Back in December 2017, when its price reached...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>[Do your bitcoins really exist?, The answer mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>[Renowned investor Gary Shilling believes Bitc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05</th>\n",
       "      <td>[Coinbase and Its Troubling History of Custome...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      maintext\n",
       "date_google                                                   \n",
       "2019-01-01   [Cryptocurrency exchange HitBTC has frozen its...\n",
       "2019-01-02   [Back in December 2017, when its price reached...\n",
       "2019-01-03   [Do your bitcoins really exist?, The answer mi...\n",
       "2019-01-04   [Renowned investor Gary Shilling believes Bitc...\n",
       "2019-01-05   [Coinbase and Its Troubling History of Custome..."
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_pickle(split_sentences,\"sentences/TSLA_articles\", protocol = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_sentences = pd.read_pickle(\"sentences/BTC_articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-for-tf2 not installed\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New tokens to be added:  ['bitcoin', 'cryptocurrency', 'crypto', 'cryptocurrencies', 'blockchain', 'bitcoin’s', 'btc']\n"
     ]
    }
   ],
   "source": [
    "keywords_bitcoin = [\"crypto\", \"BTC\", \"bitcoin\", \"blockchain\"]\n",
    "keywords_tesla =   [\"tesla\", \"Elon\", \"Musk\", \"TSLA\"]\n",
    "raw_text = \"\".join(text.values).replace(\".com\",\"-com\").replace(\".\", \"\").replace(\",\", \"\").replace(\"“\", \"\").replace(\"”\", \"\").replace(\"\\n\", \" \").replace(\"-com\",\".com\")\n",
    "new_tokens = find_new_token_with_custom_keywords(text.values, keywords_bitcoin, 6, [\"btc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AlbertTokenizer\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "tokenizer.add_tokens(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ret = label_transformer(prices.copy(), shift = 1)\n",
    "\n",
    "split_sentences, df_ret = series_intersection(split_sentences, df_ret)\n",
    "raw_sentences, raw_labels = generate_data_for_tokenizer(split_sentences,df_ret)\n",
    "\n",
    "lengths = raw_sentences.apply(lambda x: len(x[0].split()), axis = 1)\n",
    "sentences = raw_sentences[(lengths > 10) & (lengths < 120)] #filter short and long sentences\n",
    "labels = raw_labels[(lengths > 10) & (lengths < 120)]\n",
    "\n",
    "threshold = \"2020-01-01\"\n",
    "train_sentences = sentences.loc[:\"2019-12-31\"]\n",
    "test_sentences = sentences.loc[\"2020-01-01\":]\n",
    "train_labels = labels.loc[:\"2019-12-31\"]\n",
    "test_labels = labels.loc[\"2020-01-01\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lengths, bins = 100)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The answer might seem like an obvious “yes,” but the brewing “Proof of Keys” movement, launching today, argues the answer is not so clear.']\n",
      "['▁the', '▁answer', '▁might', '▁seem', '▁like', '▁an', '▁obvious', '▁', '“', 'yes', ',', '”', '▁but', '▁the', '▁brewing', '▁', '“', 'proof', '▁of', '▁keys', '”', '▁movement', ',', '▁launching', '▁today', ',', '▁argues', '▁the', '▁answer', '▁is', '▁not', '▁so', '▁clear', '.']\n"
     ]
    }
   ],
   "source": [
    "print(train_sentences.values[0])\n",
    "print(tokenizer.tokenize(train_sentences.values[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 80\n",
    "train_input_ids, train_input_masks, train_segment_ids = convert_sentences_to_features(train_sentences.values.flatten(), tokenizer, max_seq_length)\n",
    "test_input_ids, test_input_masks, test_segment_ids = convert_sentences_to_features(test_sentences.values.flatten(), tokenizer, max_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“I think most companies and individuals will operate normally with no significant interruptions, the bitcoin network will be strengthened in its decentralization properties, and many individuals and the community will have a sense of accomplishment and camaraderie,” Mayer told CoinDesk.']\n",
      "[2, 13, 1, 49, 277, 127, 1532, 17, 1883, 129, 4055, 4147, 29, 90, 1505, 21786, 18, 15, 14, 30000, 982, 129, 44, 15908, 19, 82, 121, 6306, 1829, 3704, 15, 17, 151, 1883, 17, 14, 514, 129, 57, 21, 1259, 16, 26446, 17, 16787, 13065, 3272, 15, 1, 123, 106, 470, 8646, 3196, 197, 9, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "i = 32\n",
    "print(train_sentences.values[i])\n",
    "print(train_input_ids[i])\n",
    "print(train_input_masks[i])\n",
    "print(train_segment_ids[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we want to permute training inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(train_input_ids)\n",
    "p = np.random.permutation(size)\n",
    "train_input_ids = np.array(train_input_ids)[p]\n",
    "train_input_masks = np.array(train_input_masks)[p]\n",
    "train_segment_ids = np.array(train_segment_ids)[p]\n",
    "train_labels = pd.DataFrame(train_labels.values[p], index = train_labels.index[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = {\n",
    "     \"input_ids\": np.array(train_input_ids),\n",
    "     \"input_mask\": np.array(train_input_masks),\n",
    "     \"segment_ids\": np.array(train_segment_ids),\n",
    "     }\n",
    "\n",
    "test_inputs = {\n",
    "     \"input_ids\": np.array(test_input_ids),\n",
    "     \"input_mask\": np.array(test_input_masks ),\n",
    "     \"segment_ids\": np.array(test_segment_ids),\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.where(train_labels > 0, 1, 0)\n",
    "y_test  = np.where(test_labels  > 0, 1, 0)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False )\n",
    "y_train_ohe = ohe.fit_transform(y_train)\n",
    "y_test_ohe = ohe.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/analytics-vidhya/bert-in-keras-tensorflow-2-0-using-tfhub-huggingface-81c08c5f81d8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from transformers import TFAlbertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'inception' from 'C:\\\\Users\\\\HPfamiliaRuiz-Tagle\\\\Documents\\\\JUAN_LUIS\\\\stock-prediction-nlp\\\\inception.py'>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import inception\n",
    "reload(inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(max_seq_length):\n",
    "    # Build model\n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "    input_masks = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "    input_segments = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    bert_inputs = [input_word_ids, input_masks, input_segments]\n",
    "    \n",
    "    albert_inputs = dict(input_ids=input_word_ids, input_mask=input_masks, segment_ids=input_segments)\n",
    "    \n",
    "    #albert_model = TFAlbertModel.from_pretrained(\"albert-base-v2\")\n",
    "    #sequence_output, pooled_output = albert_model([input_word_ids, input_masks, input_segments])\n",
    "    \n",
    "    \n",
    "    hub_url = \"https://tfhub.dev/google/albert_base/3\"\n",
    "    albert = hub.KerasLayer(hub_url, trainable=False, signature=\"tokens\", signature_outputs_as_dict =True)\n",
    "    \n",
    "    albert_outputs = albert(albert_inputs)\n",
    "    pooled_output = albert_outputs[\"pooled_output\"]\n",
    "    sequence_output = albert_outputs[\"sequence_output\"]\n",
    "    \n",
    "   \n",
    "    #INCEPTION\n",
    "    inception_model  = inception.Classifier_INCEPTION(\"models/\",[max_seq_length,768],2, verbose = True, nb_epochs = 1500, build = False)\n",
    "    inception_output_tensor = inception_model.build_layer_structure(sequence_output)\n",
    "\n",
    "    \n",
    "    # Build the rest of the classifier \n",
    "    dense = tf.keras.layers.Dense(max_seq_length, activation='relu')(inception_output_tensor)\n",
    "    #dense = tf.keras.layers.Dense(max_seq_length, activation='relu')(dense)\n",
    "    pred = tf.keras.layers.Dense(2, activation = 'sigmoid', name = \"output\")(dense)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs= albert_inputs, outputs= pred)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(train_input_ids) == len(train_labels))\n",
    "print(len(test_input_ids) == len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "albert_model = build_model(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_22 (KerasLayer)     {'sequence_output':  11812272    input_ids[0][0]                  \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_368 (Conv1D)             (None, None, 32)     24576       keras_layer_22[0][1]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling1D) (None, None, 768)    0           keras_layer_22[0][1]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_369 (Conv1D)             (None, None, 32)     40960       conv1d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_370 (Conv1D)             (None, None, 32)     20480       conv1d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_371 (Conv1D)             (None, None, 32)     10240       conv1d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_372 (Conv1D)             (None, None, 32)     24576       max_pooling1d_69[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, None, 128)    0           conv1d_369[0][0]                 \n",
      "                                                                 conv1d_370[0][0]                 \n",
      "                                                                 conv1d_371[0][0]                 \n",
      "                                                                 conv1d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, 128)    512         concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, None, 128)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_373 (Conv1D)             (None, None, 32)     4096        activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling1D) (None, None, 128)    0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_374 (Conv1D)             (None, None, 32)     40960       conv1d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_375 (Conv1D)             (None, None, 32)     20480       conv1d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_376 (Conv1D)             (None, None, 32)     10240       conv1d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_377 (Conv1D)             (None, None, 32)     4096        max_pooling1d_70[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, None, 128)    0           conv1d_374[0][0]                 \n",
      "                                                                 conv1d_375[0][0]                 \n",
      "                                                                 conv1d_376[0][0]                 \n",
      "                                                                 conv1d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, 128)    512         concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, None, 128)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_378 (Conv1D)             (None, None, 32)     4096        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling1D) (None, None, 128)    0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_379 (Conv1D)             (None, None, 32)     40960       conv1d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_380 (Conv1D)             (None, None, 32)     20480       conv1d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_381 (Conv1D)             (None, None, 32)     10240       conv1d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_382 (Conv1D)             (None, None, 32)     4096        max_pooling1d_71[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, None, 128)    0           conv1d_379[0][0]                 \n",
      "                                                                 conv1d_380[0][0]                 \n",
      "                                                                 conv1d_381[0][0]                 \n",
      "                                                                 conv1d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_383 (Conv1D)             (None, None, 128)    98304       keras_layer_22[0][1]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, 128)    512         concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, 128)    512         conv1d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, None, 128)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, 128)    0           batch_normalization_94[0][0]     \n",
      "                                                                 activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, None, 128)    0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_384 (Conv1D)             (None, None, 32)     4096        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling1D) (None, None, 128)    0           activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_385 (Conv1D)             (None, None, 32)     40960       conv1d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_386 (Conv1D)             (None, None, 32)     20480       conv1d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_387 (Conv1D)             (None, None, 32)     10240       conv1d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_388 (Conv1D)             (None, None, 32)     4096        max_pooling1d_72[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, None, 128)    0           conv1d_385[0][0]                 \n",
      "                                                                 conv1d_386[0][0]                 \n",
      "                                                                 conv1d_387[0][0]                 \n",
      "                                                                 conv1d_388[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, None, 128)    512         concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, None, 128)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_389 (Conv1D)             (None, None, 32)     4096        activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling1D) (None, None, 128)    0           activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_390 (Conv1D)             (None, None, 32)     40960       conv1d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_391 (Conv1D)             (None, None, 32)     20480       conv1d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_392 (Conv1D)             (None, None, 32)     10240       conv1d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_393 (Conv1D)             (None, None, 32)     4096        max_pooling1d_73[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, None, 128)    0           conv1d_390[0][0]                 \n",
      "                                                                 conv1d_391[0][0]                 \n",
      "                                                                 conv1d_392[0][0]                 \n",
      "                                                                 conv1d_393[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, None, 128)    512         concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, None, 128)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_394 (Conv1D)             (None, None, 32)     4096        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_74 (MaxPooling1D) (None, None, 128)    0           activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_395 (Conv1D)             (None, None, 32)     40960       conv1d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_396 (Conv1D)             (None, None, 32)     20480       conv1d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_397 (Conv1D)             (None, None, 32)     10240       conv1d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_398 (Conv1D)             (None, None, 32)     4096        max_pooling1d_74[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, None, 128)    0           conv1d_395[0][0]                 \n",
      "                                                                 conv1d_396[0][0]                 \n",
      "                                                                 conv1d_397[0][0]                 \n",
      "                                                                 conv1d_398[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_399 (Conv1D)             (None, None, 128)    98304       keras_layer_22[0][1]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, None, 128)    512         concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, None, 128)    512         conv1d_399[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, None, 128)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, 128)    0           batch_normalization_98[0][0]     \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, None, 128)    0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 128)          0           activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 80)           10320       global_average_pooling1d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            162         dense_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 12,543,650\n",
      "Trainable params: 729,330\n",
      "Non-trainable params: 11,814,320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "albert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-20 23:49:36.942581\n",
      "Epoch 1/20\n",
      "2517/2517 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.5355WARNING:tensorflow:Model was constructed with shape (None, 120) for input Tensor(\"input_ids_12:0\", shape=(None, 120), dtype=int32), but it was called on an input with incompatible shape (None, 80).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 120) for input Tensor(\"input_ids_12:0\", shape=(None, 120), dtype=int32), but it was called on an input with incompatible shape (None, 80).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 120) for input Tensor(\"input_mask_12:0\", shape=(None, 120), dtype=int32), but it was called on an input with incompatible shape (None, 80).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 120) for input Tensor(\"input_mask_12:0\", shape=(None, 120), dtype=int32), but it was called on an input with incompatible shape (None, 80).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 120) for input Tensor(\"segment_ids_12:0\", shape=(None, 120), dtype=int32), but it was called on an input with incompatible shape (None, 80).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 120) for input Tensor(\"segment_ids_12:0\", shape=(None, 120), dtype=int32), but it was called on an input with incompatible shape (None, 80).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2517/2517 [==============================] - 760s 302ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6971 - val_accuracy: 0.4855\n",
      "Epoch 2/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6906 - accuracy: 0.5355 - val_loss: 0.6987 - val_accuracy: 0.4855\n",
      "Epoch 3/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6975 - val_accuracy: 0.4855\n",
      "Epoch 4/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6973 - val_accuracy: 0.4855\n",
      "Epoch 5/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6906 - accuracy: 0.5355 - val_loss: 0.6987 - val_accuracy: 0.4855\n",
      "Epoch 6/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6977 - val_accuracy: 0.4855\n",
      "Epoch 7/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6975 - val_accuracy: 0.4855\n",
      "Epoch 8/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6978 - val_accuracy: 0.4855\n",
      "Epoch 9/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6966 - val_accuracy: 0.4855\n",
      "Epoch 10/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6973 - val_accuracy: 0.4855\n",
      "Epoch 11/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6976 - val_accuracy: 0.4855\n",
      "Epoch 12/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6965 - val_accuracy: 0.4855\n",
      "Epoch 13/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6983 - val_accuracy: 0.4855\n",
      "Epoch 14/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6976 - val_accuracy: 0.4855\n",
      "Epoch 15/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6972 - val_accuracy: 0.4855\n",
      "Epoch 16/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6975 - val_accuracy: 0.4855\n",
      "Epoch 17/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6991 - val_accuracy: 0.4855\n",
      "Epoch 18/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6977 - val_accuracy: 0.4855\n",
      "Epoch 19/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6906 - accuracy: 0.5355 - val_loss: 0.6962 - val_accuracy: 0.4855\n",
      "Epoch 20/20\n",
      "2517/2517 [==============================] - 758s 301ms/step - loss: 0.6907 - accuracy: 0.5355 - val_loss: 0.6966 - val_accuracy: 0.4855\n",
      "-1 day, 19:47:14.278782\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "print(start)\n",
    "\n",
    "history = bert_model.fit(x = train_inputs, \n",
    "    y = y_train_ohe,\n",
    "    validation_data=(test_inputs, y_test_ohe),\n",
    "    epochs=20,\n",
    "    batch_size=16\n",
    ")\n",
    "end = datetime.datetime.now()\n",
    "print(start - end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = albert_model.predict(test_inputs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8425, 2)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions.T[0])\n",
    "plt.plot(test_labels.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"bitcoin_title_description\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"features_labels/train_bert_{}_output_pooled\".format(name),train_bert_output[0])\n",
    "np.save(\"features_labels/train_bert_{}_output_sequence\".format(name),train_bert_output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"features_labels/test_bert_{}_output_pooled\".format(name),test_bert_output[0])\n",
    "np.save(\"features_labels/test_bert_{}_output_sequence\".format(name),test_bert_output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = \"bitcoin_ret1days\"\n",
    "pd.to_pickle(train_labels, \"features_labels/train_{}_labels\".format(label_name))\n",
    "pd.to_pickle(test_labels, \"features_labels/test_{}_labels\".format(label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40522, 768)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bert_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40522, 120)\n",
      "(40522, 120)\n",
      "(40522, 120)\n"
     ]
    }
   ],
   "source": [
    "print(train_inputs[\"input_ids\"].shape)\n",
    "print(train_inputs[\"input_mask\"].shape)\n",
    "print(train_inputs[\"segment_ids\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://ieeexplore.ieee.org/document/8141873\n",
    "- https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "- https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception import Classifier_INCEPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 80424960 into shape (2618,1,40)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-4795bfa47fc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_tr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train_tr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test_tr\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mX_test_tr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_tr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test_tr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 80424960 into shape (2618,1,40)"
     ]
    }
   ],
   "source": [
    "X_train_tr = X_train_tr.reshape(X_train_tr.shape[0],1,X_train_tr.shape[1])\n",
    "X_test_tr  = X_test_tr.reshape(X_test_tr.shape[0], 1,X_test_tr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "41/41 [==============================] - 2s 55ms/step - loss: 0.7708 - accuracy: 0.5034 - val_loss: 1.1733 - val_accuracy: 0.4864 - lr: 0.0010\n",
      "Epoch 2/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.6326 - accuracy: 0.6524 - val_loss: 0.7902 - val_accuracy: 0.4928 - lr: 0.0010\n",
      "Epoch 3/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.5331 - accuracy: 0.7594 - val_loss: 0.8429 - val_accuracy: 0.5104 - lr: 0.0010\n",
      "Epoch 4/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.3958 - accuracy: 0.8304 - val_loss: 1.0313 - val_accuracy: 0.5136 - lr: 0.0010\n",
      "Epoch 5/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.2362 - accuracy: 0.9106 - val_loss: 1.2369 - val_accuracy: 0.4944 - lr: 0.0010\n",
      "Epoch 6/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1371 - accuracy: 0.9488 - val_loss: 1.3672 - val_accuracy: 0.5024 - lr: 0.0010\n",
      "Epoch 7/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0887 - accuracy: 0.9756 - val_loss: 2.4096 - val_accuracy: 0.5104 - lr: 0.0010\n",
      "Epoch 8/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0609 - accuracy: 0.9855 - val_loss: 1.6717 - val_accuracy: 0.4928 - lr: 0.0010\n",
      "Epoch 9/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0451 - accuracy: 0.9851 - val_loss: 1.9281 - val_accuracy: 0.5104 - lr: 0.0010\n",
      "Epoch 10/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 2.1671 - val_accuracy: 0.4944 - lr: 0.0010\n",
      "Epoch 11/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0162 - accuracy: 0.9958 - val_loss: 1.8788 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 12/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 2.1522 - val_accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 13/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 2.0931 - val_accuracy: 0.4976 - lr: 0.0010\n",
      "Epoch 14/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0069 - accuracy: 0.9962 - val_loss: 2.0176 - val_accuracy: 0.4944 - lr: 0.0010\n",
      "Epoch 15/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0067 - accuracy: 0.9958 - val_loss: 2.0743 - val_accuracy: 0.4896 - lr: 0.0010\n",
      "Epoch 16/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0065 - accuracy: 0.9958 - val_loss: 2.0350 - val_accuracy: 0.4799 - lr: 0.0010\n",
      "Epoch 17/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0054 - accuracy: 0.9958 - val_loss: 2.0209 - val_accuracy: 0.4896 - lr: 0.0010\n",
      "Epoch 18/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0051 - accuracy: 0.9966 - val_loss: 1.9983 - val_accuracy: 0.4960 - lr: 0.0010\n",
      "Epoch 19/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0050 - accuracy: 0.9962 - val_loss: 1.9934 - val_accuracy: 0.4751 - lr: 0.0010\n",
      "Epoch 20/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0051 - accuracy: 0.9958 - val_loss: 2.0083 - val_accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 21/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0064 - accuracy: 0.9958 - val_loss: 2.0246 - val_accuracy: 0.4880 - lr: 0.0010\n",
      "Epoch 22/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0053 - accuracy: 0.9958 - val_loss: 2.0745 - val_accuracy: 0.4864 - lr: 0.0010\n",
      "Epoch 23/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0056 - accuracy: 0.9962 - val_loss: 2.1171 - val_accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 24/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0048 - accuracy: 0.9954 - val_loss: 2.0707 - val_accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 25/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0047 - accuracy: 0.9962 - val_loss: 2.0812 - val_accuracy: 0.4928 - lr: 0.0010\n",
      "Epoch 26/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0051 - accuracy: 0.9958 - val_loss: 2.0857 - val_accuracy: 0.4912 - lr: 0.0010\n",
      "Epoch 27/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 2.1102 - val_accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 28/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0050 - accuracy: 0.9966 - val_loss: 2.1173 - val_accuracy: 0.4960 - lr: 0.0010\n",
      "Epoch 29/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0046 - accuracy: 0.9966 - val_loss: 2.1203 - val_accuracy: 0.4944 - lr: 0.0010\n",
      "Epoch 30/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0047 - accuracy: 0.9966 - val_loss: 2.1433 - val_accuracy: 0.4767 - lr: 0.0010\n",
      "Epoch 31/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0047 - accuracy: 0.9966 - val_loss: 2.1987 - val_accuracy: 0.4928 - lr: 0.0010\n",
      "Epoch 32/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9966 - val_loss: 2.1788 - val_accuracy: 0.4880 - lr: 0.0010\n",
      "Epoch 33/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 2.1839 - val_accuracy: 0.4831 - lr: 0.0010\n",
      "Epoch 34/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 2.1782 - val_accuracy: 0.4799 - lr: 0.0010\n",
      "Epoch 35/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0044 - accuracy: 0.9962 - val_loss: 2.1747 - val_accuracy: 0.4799 - lr: 0.0010\n",
      "Epoch 36/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 2.2903 - val_accuracy: 0.4944 - lr: 0.0010\n",
      "Epoch 37/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0042 - accuracy: 0.9969 - val_loss: 2.1956 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 38/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0046 - accuracy: 0.9958 - val_loss: 2.2065 - val_accuracy: 0.4751 - lr: 0.0010\n",
      "Epoch 39/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 2.2289 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 40/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0043 - accuracy: 0.9973 - val_loss: 2.2009 - val_accuracy: 0.4912 - lr: 0.0010\n",
      "Epoch 41/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0045 - accuracy: 0.9954 - val_loss: 2.2175 - val_accuracy: 0.4799 - lr: 0.0010\n",
      "Epoch 42/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0043 - accuracy: 0.9969 - val_loss: 2.2329 - val_accuracy: 0.4799 - lr: 0.0010\n",
      "Epoch 43/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0048 - accuracy: 0.9962 - val_loss: 2.2460 - val_accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 44/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0045 - accuracy: 0.9958 - val_loss: 2.3192 - val_accuracy: 0.4928 - lr: 0.0010\n",
      "Epoch 45/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0044 - accuracy: 0.9958 - val_loss: 2.2445 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 46/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0044 - accuracy: 0.9962 - val_loss: 2.2578 - val_accuracy: 0.4767 - lr: 0.0010\n",
      "Epoch 47/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0045 - accuracy: 0.9962 - val_loss: 2.2705 - val_accuracy: 0.4799 - lr: 0.0010\n",
      "Epoch 48/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0045 - accuracy: 0.9966 - val_loss: 2.2634 - val_accuracy: 0.4864 - lr: 0.0010\n",
      "Epoch 49/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 2.2870 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 50/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9962 - val_loss: 2.2639 - val_accuracy: 0.4880 - lr: 0.0010\n",
      "Epoch 51/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0045 - accuracy: 0.9958 - val_loss: 2.3115 - val_accuracy: 0.4735 - lr: 0.0010\n",
      "Epoch 52/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0041 - accuracy: 0.9962 - val_loss: 2.3442 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 53/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0045 - accuracy: 0.9966 - val_loss: 2.3212 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 54/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0042 - accuracy: 0.9966 - val_loss: 2.3371 - val_accuracy: 0.4735 - lr: 0.0010\n",
      "Epoch 55/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0040 - accuracy: 0.9966 - val_loss: 2.3015 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 56/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9966 - val_loss: 2.3300 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 57/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9966 - val_loss: 2.3081 - val_accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 58/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0042 - accuracy: 0.9969 - val_loss: 2.3403 - val_accuracy: 0.4799 - lr: 0.0010\n",
      "Epoch 59/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0045 - accuracy: 0.9962 - val_loss: 2.3742 - val_accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 60/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0042 - accuracy: 0.9969 - val_loss: 2.3702 - val_accuracy: 0.4896 - lr: 0.0010\n",
      "Epoch 61/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9966 - val_loss: 2.4121 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 62/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0043 - accuracy: 0.9969 - val_loss: 2.4040 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 63/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0042 - accuracy: 0.9973 - val_loss: 2.3662 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 64/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9969 - val_loss: 2.3997 - val_accuracy: 0.4767 - lr: 0.0010\n",
      "Epoch 65/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9973 - val_loss: 2.3729 - val_accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 66/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9962 - val_loss: 2.3827 - val_accuracy: 0.4896 - lr: 0.0010\n",
      "Epoch 67/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9966 - val_loss: 2.3847 - val_accuracy: 0.4928 - lr: 0.0010\n",
      "Epoch 68/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9962 - val_loss: 2.4041 - val_accuracy: 0.4799 - lr: 0.0010\n",
      "Epoch 69/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0043 - accuracy: 0.9966 - val_loss: 2.9172 - val_accuracy: 0.4976 - lr: 0.0010\n",
      "Epoch 70/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0055 - accuracy: 0.9973 - val_loss: 3.3926 - val_accuracy: 0.5297 - lr: 0.0010\n",
      "Epoch 71/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.4382 - accuracy: 0.7850 - val_loss: 5.2627 - val_accuracy: 0.5104 - lr: 0.0010\n",
      "Epoch 72/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.4991 - accuracy: 0.7590 - val_loss: 1.4567 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 73/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.2756 - accuracy: 0.8812 - val_loss: 1.9931 - val_accuracy: 0.4880 - lr: 0.0010\n",
      "Epoch 74/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.1706 - accuracy: 0.9312 - val_loss: 1.6355 - val_accuracy: 0.4735 - lr: 0.0010\n",
      "Epoch 75/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.1086 - accuracy: 0.9618 - val_loss: 2.1929 - val_accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 76/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0565 - accuracy: 0.9843 - val_loss: 1.8444 - val_accuracy: 0.4767 - lr: 0.0010\n",
      "Epoch 77/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0395 - accuracy: 0.9859 - val_loss: 2.0784 - val_accuracy: 0.4751 - lr: 0.0010\n",
      "Epoch 78/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0209 - accuracy: 0.9920 - val_loss: 2.0536 - val_accuracy: 0.4976 - lr: 0.0010\n",
      "Epoch 79/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 2.1871 - val_accuracy: 0.4928 - lr: 0.0010\n",
      "Epoch 80/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0079 - accuracy: 0.9958 - val_loss: 2.2880 - val_accuracy: 0.4896 - lr: 0.0010\n",
      "Epoch 81/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0059 - accuracy: 0.9973 - val_loss: 2.3410 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 82/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0054 - accuracy: 0.9969 - val_loss: 2.3620 - val_accuracy: 0.4719 - lr: 0.0010\n",
      "Epoch 83/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0055 - accuracy: 0.9973 - val_loss: 2.3694 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 84/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0052 - accuracy: 0.9973 - val_loss: 2.3940 - val_accuracy: 0.4687 - lr: 0.0010\n",
      "Epoch 85/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 2.4240 - val_accuracy: 0.4687 - lr: 0.0010\n",
      "Epoch 86/1500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.0046 - accuracy: 0.9966 - val_loss: 2.4363 - val_accuracy: 0.4687 - lr: 0.0010\n",
      "Epoch 87/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0051 - accuracy: 0.9962 - val_loss: 2.5060 - val_accuracy: 0.4751 - lr: 0.0010\n",
      "Epoch 88/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0050 - accuracy: 0.9958 - val_loss: 2.5211 - val_accuracy: 0.4767 - lr: 0.0010\n",
      "Epoch 89/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0062 - accuracy: 0.9950 - val_loss: 2.4545 - val_accuracy: 0.4719 - lr: 0.0010\n",
      "Epoch 90/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0047 - accuracy: 0.9966 - val_loss: 2.4893 - val_accuracy: 0.4719 - lr: 0.0010\n",
      "Epoch 91/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0048 - accuracy: 0.9966 - val_loss: 2.5152 - val_accuracy: 0.4799 - lr: 0.0010\n",
      "Epoch 92/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0044 - accuracy: 0.9962 - val_loss: 2.5273 - val_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 93/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0045 - accuracy: 0.9973 - val_loss: 2.5458 - val_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 94/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0045 - accuracy: 0.9962 - val_loss: 2.5685 - val_accuracy: 0.4799 - lr: 0.0010\n",
      "Epoch 95/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0045 - accuracy: 0.9958 - val_loss: 2.5744 - val_accuracy: 0.4799 - lr: 0.0010\n",
      "Epoch 96/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0046 - accuracy: 0.9962 - val_loss: 2.5759 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 97/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0044 - accuracy: 0.9954 - val_loss: 2.5783 - val_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 98/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0042 - accuracy: 0.9962 - val_loss: 2.5795 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 99/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0042 - accuracy: 0.9962 - val_loss: 2.5923 - val_accuracy: 0.4719 - lr: 0.0010\n",
      "Epoch 100/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 2.5991 - val_accuracy: 0.4767 - lr: 0.0010\n",
      "Epoch 101/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9966 - val_loss: 2.6079 - val_accuracy: 0.4719 - lr: 0.0010\n",
      "Epoch 102/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0043 - accuracy: 0.9958 - val_loss: 2.6155 - val_accuracy: 0.4735 - lr: 0.0010\n",
      "Epoch 103/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0043 - accuracy: 0.9958 - val_loss: 2.6325 - val_accuracy: 0.4799 - lr: 0.0010\n",
      "Epoch 104/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9962 - val_loss: 2.6339 - val_accuracy: 0.4799 - lr: 0.0010\n",
      "Epoch 105/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0044 - accuracy: 0.9958 - val_loss: 2.6556 - val_accuracy: 0.4751 - lr: 0.0010\n",
      "Epoch 106/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9973 - val_loss: 2.6527 - val_accuracy: 0.4767 - lr: 5.0000e-04\n",
      "Epoch 107/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9966 - val_loss: 2.6518 - val_accuracy: 0.4767 - lr: 5.0000e-04\n",
      "Epoch 108/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9969 - val_loss: 2.6585 - val_accuracy: 0.4815 - lr: 5.0000e-04\n",
      "Epoch 109/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9966 - val_loss: 2.6592 - val_accuracy: 0.4799 - lr: 5.0000e-04\n",
      "Epoch 110/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9969 - val_loss: 2.6669 - val_accuracy: 0.4815 - lr: 5.0000e-04\n",
      "Epoch 111/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9969 - val_loss: 2.6743 - val_accuracy: 0.4864 - lr: 5.0000e-04\n",
      "Epoch 112/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9954 - val_loss: 2.6761 - val_accuracy: 0.4799 - lr: 5.0000e-04\n",
      "Epoch 113/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9969 - val_loss: 2.6731 - val_accuracy: 0.4783 - lr: 5.0000e-04\n",
      "Epoch 114/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9969 - val_loss: 2.6773 - val_accuracy: 0.4799 - lr: 5.0000e-04\n",
      "Epoch 115/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9966 - val_loss: 2.6860 - val_accuracy: 0.4831 - lr: 5.0000e-04\n",
      "Epoch 116/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9973 - val_loss: 2.6912 - val_accuracy: 0.4831 - lr: 5.0000e-04\n",
      "Epoch 117/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9969 - val_loss: 2.6968 - val_accuracy: 0.4815 - lr: 5.0000e-04\n",
      "Epoch 118/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9962 - val_loss: 2.7056 - val_accuracy: 0.4864 - lr: 5.0000e-04\n",
      "Epoch 119/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9958 - val_loss: 2.7105 - val_accuracy: 0.4848 - lr: 5.0000e-04\n",
      "Epoch 120/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9962 - val_loss: 2.7100 - val_accuracy: 0.4767 - lr: 5.0000e-04\n",
      "Epoch 121/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9962 - val_loss: 2.7211 - val_accuracy: 0.4799 - lr: 5.0000e-04\n",
      "Epoch 122/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9966 - val_loss: 2.7284 - val_accuracy: 0.4767 - lr: 5.0000e-04\n",
      "Epoch 123/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9973 - val_loss: 2.7341 - val_accuracy: 0.4767 - lr: 5.0000e-04\n",
      "Epoch 124/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9958 - val_loss: 2.7419 - val_accuracy: 0.4831 - lr: 5.0000e-04\n",
      "Epoch 125/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9969 - val_loss: 2.7412 - val_accuracy: 0.4815 - lr: 5.0000e-04\n",
      "Epoch 126/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9962 - val_loss: 2.7443 - val_accuracy: 0.4848 - lr: 5.0000e-04\n",
      "Epoch 127/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9962 - val_loss: 2.7477 - val_accuracy: 0.4799 - lr: 5.0000e-04\n",
      "Epoch 128/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9973 - val_loss: 2.7542 - val_accuracy: 0.4735 - lr: 5.0000e-04\n",
      "Epoch 129/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9958 - val_loss: 2.7608 - val_accuracy: 0.4831 - lr: 5.0000e-04\n",
      "Epoch 130/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0043 - accuracy: 0.9958 - val_loss: 2.7692 - val_accuracy: 0.4799 - lr: 5.0000e-04\n",
      "Epoch 131/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9962 - val_loss: 2.7751 - val_accuracy: 0.4799 - lr: 5.0000e-04\n",
      "Epoch 132/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9962 - val_loss: 2.7802 - val_accuracy: 0.4767 - lr: 5.0000e-04\n",
      "Epoch 133/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9969 - val_loss: 2.7830 - val_accuracy: 0.4687 - lr: 5.0000e-04\n",
      "Epoch 134/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9962 - val_loss: 2.7871 - val_accuracy: 0.4799 - lr: 5.0000e-04\n",
      "Epoch 135/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0042 - accuracy: 0.9966 - val_loss: 2.8011 - val_accuracy: 0.4815 - lr: 5.0000e-04\n",
      "Epoch 136/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9966 - val_loss: 2.7965 - val_accuracy: 0.4848 - lr: 5.0000e-04\n",
      "Epoch 137/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9966 - val_loss: 2.7996 - val_accuracy: 0.4783 - lr: 5.0000e-04\n",
      "Epoch 138/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9962 - val_loss: 2.8001 - val_accuracy: 0.4799 - lr: 5.0000e-04\n",
      "Epoch 139/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9962 - val_loss: 2.8052 - val_accuracy: 0.4751 - lr: 5.0000e-04\n",
      "Epoch 140/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9958 - val_loss: 2.8158 - val_accuracy: 0.4831 - lr: 5.0000e-04\n",
      "Epoch 141/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9969 - val_loss: 2.8224 - val_accuracy: 0.4815 - lr: 5.0000e-04\n",
      "Epoch 142/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0042 - accuracy: 0.9950 - val_loss: 2.8201 - val_accuracy: 0.4719 - lr: 5.0000e-04\n",
      "Epoch 143/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9966 - val_loss: 2.8291 - val_accuracy: 0.4815 - lr: 5.0000e-04\n",
      "Epoch 144/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9969 - val_loss: 2.8300 - val_accuracy: 0.4815 - lr: 5.0000e-04\n",
      "Epoch 145/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9973 - val_loss: 2.8410 - val_accuracy: 0.4831 - lr: 5.0000e-04\n",
      "Epoch 146/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9969 - val_loss: 2.8415 - val_accuracy: 0.4815 - lr: 5.0000e-04\n",
      "Epoch 147/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0043 - accuracy: 0.9962 - val_loss: 2.8550 - val_accuracy: 0.4831 - lr: 5.0000e-04\n",
      "Epoch 148/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9966 - val_loss: 2.8569 - val_accuracy: 0.4848 - lr: 5.0000e-04\n",
      "Epoch 149/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9969 - val_loss: 2.8655 - val_accuracy: 0.4751 - lr: 5.0000e-04\n",
      "Epoch 150/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9958 - val_loss: 2.8799 - val_accuracy: 0.4896 - lr: 5.0000e-04\n",
      "Epoch 151/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9969 - val_loss: 2.8834 - val_accuracy: 0.4848 - lr: 5.0000e-04\n",
      "Epoch 152/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9962 - val_loss: 2.8962 - val_accuracy: 0.4767 - lr: 5.0000e-04\n",
      "Epoch 153/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9969 - val_loss: 2.8853 - val_accuracy: 0.4815 - lr: 5.0000e-04\n",
      "Epoch 154/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9969 - val_loss: 2.8932 - val_accuracy: 0.4751 - lr: 5.0000e-04\n",
      "Epoch 155/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9958 - val_loss: 2.8957 - val_accuracy: 0.4815 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9966 - val_loss: 2.8921 - val_accuracy: 0.4767 - lr: 5.0000e-04\n",
      "Epoch 157/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9969 - val_loss: 2.9107 - val_accuracy: 0.4815 - lr: 5.0000e-04\n",
      "Epoch 158/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9966 - val_loss: 2.9204 - val_accuracy: 0.4751 - lr: 5.0000e-04\n",
      "Epoch 159/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9969 - val_loss: 2.9167 - val_accuracy: 0.4783 - lr: 5.0000e-04\n",
      "Epoch 160/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9962 - val_loss: 2.9143 - val_accuracy: 0.4783 - lr: 5.0000e-04\n",
      "Epoch 161/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9969 - val_loss: 2.9103 - val_accuracy: 0.4719 - lr: 5.0000e-04\n",
      "Epoch 162/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0041 - accuracy: 0.9958 - val_loss: 2.9122 - val_accuracy: 0.4751 - lr: 5.0000e-04\n",
      "Epoch 163/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9977 - val_loss: 2.9277 - val_accuracy: 0.4783 - lr: 5.0000e-04\n",
      "Epoch 164/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9958 - val_loss: 2.9230 - val_accuracy: 0.4848 - lr: 5.0000e-04\n",
      "Epoch 165/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9966 - val_loss: 2.9298 - val_accuracy: 0.4783 - lr: 5.0000e-04\n",
      "Epoch 166/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9966 - val_loss: 2.9328 - val_accuracy: 0.4831 - lr: 5.0000e-04\n",
      "Epoch 167/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 2.9392 - val_accuracy: 0.4767 - lr: 5.0000e-04\n",
      "Epoch 168/1500\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.99 - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9954 - val_loss: 2.9377 - val_accuracy: 0.4815 - lr: 2.5000e-04\n",
      "Epoch 169/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 2.9443 - val_accuracy: 0.4783 - lr: 2.5000e-04\n",
      "Epoch 170/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9973 - val_loss: 2.9477 - val_accuracy: 0.4815 - lr: 2.5000e-040.\n",
      "Epoch 171/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 2.9538 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 172/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 2.9584 - val_accuracy: 0.4815 - lr: 2.5000e-04\n",
      "Epoch 173/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 2.9631 - val_accuracy: 0.4864 - lr: 2.5000e-04\n",
      "Epoch 174/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 2.9639 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 175/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 2.9685 - val_accuracy: 0.4815 - lr: 2.5000e-04\n",
      "Epoch 176/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 2.9659 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 177/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 2.9716 - val_accuracy: 0.4864 - lr: 2.5000e-04\n",
      "Epoch 178/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9962 - val_loss: 2.9746 - val_accuracy: 0.4799 - lr: 2.5000e-04\n",
      "Epoch 179/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9954 - val_loss: 2.9772 - val_accuracy: 0.4864 - lr: 2.5000e-04\n",
      "Epoch 180/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 2.9822 - val_accuracy: 0.4799 - lr: 2.5000e-04\n",
      "Epoch 181/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9969 - val_loss: 2.9821 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 182/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9973 - val_loss: 2.9899 - val_accuracy: 0.4815 - lr: 2.5000e-04\n",
      "Epoch 183/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9969 - val_loss: 2.9908 - val_accuracy: 0.4848 - lr: 2.5000e-04\n",
      "Epoch 184/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 2.9983 - val_accuracy: 0.4864 - lr: 2.5000e-04\n",
      "Epoch 185/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9958 - val_loss: 3.0101 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 186/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 2.9999 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 187/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.0013 - val_accuracy: 0.4848 - lr: 2.5000e-04\n",
      "Epoch 188/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9966 - val_loss: 3.0095 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 189/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9969 - val_loss: 2.9972 - val_accuracy: 0.4848 - lr: 2.5000e-04\n",
      "Epoch 190/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9966 - val_loss: 2.9982 - val_accuracy: 0.4896 - lr: 2.5000e-04\n",
      "Epoch 191/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.0024 - val_accuracy: 0.4864 - lr: 2.5000e-04\n",
      "Epoch 192/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9958 - val_loss: 3.0023 - val_accuracy: 0.4864 - lr: 2.5000e-04\n",
      "Epoch 193/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.0094 - val_accuracy: 0.4848 - lr: 2.5000e-04\n",
      "Epoch 194/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9962 - val_loss: 3.0151 - val_accuracy: 0.4864 - lr: 2.5000e-04\n",
      "Epoch 195/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9962 - val_loss: 3.0229 - val_accuracy: 0.4815 - lr: 2.5000e-04\n",
      "Epoch 196/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9966 - val_loss: 3.0266 - val_accuracy: 0.4848 - lr: 2.5000e-04\n",
      "Epoch 197/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.0351 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 198/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9969 - val_loss: 3.0394 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 199/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9966 - val_loss: 3.0424 - val_accuracy: 0.4880 - lr: 2.5000e-04\n",
      "Epoch 200/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.0488 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 201/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.0551 - val_accuracy: 0.4799 - lr: 2.5000e-04\n",
      "Epoch 202/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9958 - val_loss: 3.0572 - val_accuracy: 0.4799 - lr: 2.5000e-04\n",
      "Epoch 203/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.0595 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 204/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.0640 - val_accuracy: 0.4799 - lr: 2.5000e-04\n",
      "Epoch 205/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9969 - val_loss: 3.0685 - val_accuracy: 0.4799 - lr: 2.5000e-04\n",
      "Epoch 206/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.0690 - val_accuracy: 0.4799 - lr: 2.5000e-04\n",
      "Epoch 207/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9966 - val_loss: 3.0703 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 208/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9969 - val_loss: 3.0753 - val_accuracy: 0.4848 - lr: 2.5000e-04\n",
      "Epoch 209/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.0768 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 210/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9958 - val_loss: 3.0843 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 211/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.0967 - val_accuracy: 0.4815 - lr: 2.5000e-04\n",
      "Epoch 212/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.0968 - val_accuracy: 0.4831 - lr: 2.5000e-04\n",
      "Epoch 213/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.0995 - val_accuracy: 0.4815 - lr: 2.5000e-04\n",
      "Epoch 214/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9954 - val_loss: 3.1072 - val_accuracy: 0.4864 - lr: 2.5000e-04\n",
      "Epoch 215/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.1083 - val_accuracy: 0.4864 - lr: 2.5000e-04\n",
      "Epoch 216/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9969 - val_loss: 3.1051 - val_accuracy: 0.4848 - lr: 2.5000e-04\n",
      "Epoch 217/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.1140 - val_accuracy: 0.4799 - lr: 2.5000e-04\n",
      "Epoch 218/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9962 - val_loss: 3.1224 - val_accuracy: 0.4815 - lr: 2.5000e-04\n",
      "Epoch 219/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.1216 - val_accuracy: 0.4799 - lr: 2.5000e-04\n",
      "Epoch 220/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.1237 - val_accuracy: 0.4799 - lr: 1.2500e-04\n",
      "Epoch 221/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9954 - val_loss: 3.1339 - val_accuracy: 0.4864 - lr: 1.2500e-04\n",
      "Epoch 222/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 3.1296 - val_accuracy: 0.4848 - lr: 1.2500e-04\n",
      "Epoch 223/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9954 - val_loss: 3.1381 - val_accuracy: 0.4864 - lr: 1.2500e-04\n",
      "Epoch 224/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.1575 - val_accuracy: 0.4719 - lr: 1.2500e-04\n",
      "Epoch 225/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.1560 - val_accuracy: 0.4719 - lr: 1.2500e-04\n",
      "Epoch 226/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.1526 - val_accuracy: 0.4799 - lr: 1.2500e-04\n",
      "Epoch 227/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.1560 - val_accuracy: 0.4751 - lr: 1.2500e-04\n",
      "Epoch 228/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.1554 - val_accuracy: 0.4815 - lr: 1.2500e-04\n",
      "Epoch 229/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.1580 - val_accuracy: 0.4751 - lr: 1.2500e-04\n",
      "Epoch 230/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.1572 - val_accuracy: 0.4735 - lr: 1.2500e-04\n",
      "Epoch 231/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 3.1572 - val_accuracy: 0.4815 - lr: 1.2500e-04\n",
      "Epoch 232/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.1640 - val_accuracy: 0.4767 - lr: 1.2500e-04\n",
      "Epoch 233/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9954 - val_loss: 3.1621 - val_accuracy: 0.4880 - lr: 1.2500e-04\n",
      "Epoch 234/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.1650 - val_accuracy: 0.4815 - lr: 1.2500e-04\n",
      "Epoch 235/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.1691 - val_accuracy: 0.4799 - lr: 1.2500e-04\n",
      "Epoch 236/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.1668 - val_accuracy: 0.4799 - lr: 1.2500e-04\n",
      "Epoch 237/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.1642 - val_accuracy: 0.4767 - lr: 1.2500e-04\n",
      "Epoch 238/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 3.1666 - val_accuracy: 0.4767 - lr: 1.2500e-04\n",
      "Epoch 239/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 3.1704 - val_accuracy: 0.4751 - lr: 1.2500e-04\n",
      "Epoch 240/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.1751 - val_accuracy: 0.4783 - lr: 1.2500e-04\n",
      "Epoch 241/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.1843 - val_accuracy: 0.4735 - lr: 1.2500e-04\n",
      "Epoch 242/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.1752 - val_accuracy: 0.4864 - lr: 1.2500e-04\n",
      "Epoch 243/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.1788 - val_accuracy: 0.4864 - lr: 1.2500e-04\n",
      "Epoch 244/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.1754 - val_accuracy: 0.4864 - lr: 1.2500e-04\n",
      "Epoch 245/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.1751 - val_accuracy: 0.4864 - lr: 1.2500e-04\n",
      "Epoch 246/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.1799 - val_accuracy: 0.4799 - lr: 1.2500e-04\n",
      "Epoch 247/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.1945 - val_accuracy: 0.4799 - lr: 1.2500e-04\n",
      "Epoch 248/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9966 - val_loss: 3.1986 - val_accuracy: 0.4799 - lr: 1.2500e-04\n",
      "Epoch 249/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.1994 - val_accuracy: 0.4864 - lr: 1.2500e-04\n",
      "Epoch 250/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0039 - accuracy: 0.9966 - val_loss: 3.2042 - val_accuracy: 0.4880 - lr: 1.2500e-04\n",
      "Epoch 251/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 3.2016 - val_accuracy: 0.4831 - lr: 1.2500e-04\n",
      "Epoch 252/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.2043 - val_accuracy: 0.4880 - lr: 1.2500e-04\n",
      "Epoch 253/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 3.2067 - val_accuracy: 0.4848 - lr: 1.2500e-04\n",
      "Epoch 254/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0039 - accuracy: 0.9966 - val_loss: 3.2096 - val_accuracy: 0.4815 - lr: 1.2500e-04\n",
      "Epoch 255/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.2144 - val_accuracy: 0.4831 - lr: 1.2500e-04\n",
      "Epoch 256/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.2187 - val_accuracy: 0.4831 - lr: 1.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.2232 - val_accuracy: 0.4831 - lr: 1.2500e-04\n",
      "Epoch 258/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9958 - val_loss: 3.2273 - val_accuracy: 0.4815 - lr: 1.2500e-04\n",
      "Epoch 259/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.2336 - val_accuracy: 0.4815 - lr: 1.2500e-04\n",
      "Epoch 260/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.2346 - val_accuracy: 0.4799 - lr: 1.2500e-04\n",
      "Epoch 261/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.2409 - val_accuracy: 0.4815 - lr: 1.2500e-04\n",
      "Epoch 262/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.2328 - val_accuracy: 0.4767 - lr: 1.2500e-04\n",
      "Epoch 263/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.2377 - val_accuracy: 0.4783 - lr: 1.2500e-04\n",
      "Epoch 264/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.2497 - val_accuracy: 0.4783 - lr: 1.2500e-04\n",
      "Epoch 265/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.2495 - val_accuracy: 0.4783 - lr: 1.2500e-04\n",
      "Epoch 266/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.2505 - val_accuracy: 0.4767 - lr: 1.2500e-04\n",
      "Epoch 267/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.2510 - val_accuracy: 0.4751 - lr: 1.2500e-04\n",
      "Epoch 268/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.2655 - val_accuracy: 0.4799 - lr: 1.2500e-04\n",
      "Epoch 269/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.2701 - val_accuracy: 0.4783 - lr: 1.2500e-04\n",
      "Epoch 270/1500\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.99 - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.2612 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 271/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.2751 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 272/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.2641 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 273/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.2695 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 274/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.2668 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 275/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 3.2718 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 276/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.2769 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 277/1500\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.99 - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.2796 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 278/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.2809 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 279/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9954 - val_loss: 3.2793 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 280/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 3.2928 - val_accuracy: 0.4719 - lr: 1.0000e-04\n",
      "Epoch 281/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.2790 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 282/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9950 - val_loss: 3.2899 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 283/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.2965 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 284/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9958 - val_loss: 3.3027 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 285/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.3004 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 286/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 3.3001 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 287/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.3040 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 288/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.3073 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 289/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.3133 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 290/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.3134 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 291/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.3164 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 292/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.3169 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 293/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9954 - val_loss: 3.3184 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 294/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 3.3213 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 295/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.3263 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 296/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.3283 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 297/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.3410 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 298/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 3.3361 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 299/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.3381 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 300/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.3422 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 301/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.3386 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 302/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.3567 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 303/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.3474 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 304/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9954 - val_loss: 3.3598 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 305/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.3630 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 306/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.3609 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 307/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.3766 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 308/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.3739 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 309/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.3777 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 310/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.3933 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 311/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.4060 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 312/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.3955 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 313/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 3.3867 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 314/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.3841 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 315/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.3945 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 316/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.4018 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 317/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.3935 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 318/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9962 - val_loss: 3.4133 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 319/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 3.4122 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 320/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.4079 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 321/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.4297 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 322/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.4411 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 323/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.4223 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 324/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9954 - val_loss: 3.4155 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 325/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 3.4111 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 326/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 3.4401 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 327/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.4592 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 328/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.4574 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 329/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 3.4469 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 330/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.4510 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 331/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.4657 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 332/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.4597 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 333/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.4540 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 334/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.4511 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 335/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.4587 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 336/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.4716 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 337/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.4865 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 338/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.4826 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 339/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9950 - val_loss: 3.4906 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 340/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.4872 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 341/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.5175 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 342/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 3.5136 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 343/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.5004 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 344/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.5109 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 345/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.5364 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 346/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9954 - val_loss: 3.5469 - val_accuracy: 0.4703 - lr: 1.0000e-04\n",
      "Epoch 347/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.5380 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 348/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 3.5352 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 349/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.5491 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 350/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.5370 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 351/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.5650 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 352/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.5715 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 353/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.5871 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 354/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.5906 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 355/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.5663 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 356/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.5584 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 357/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.5607 - val_accuracy: 0.4815 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.5676 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 359/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 3.5926 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 360/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.5874 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 361/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.5802 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 362/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.5840 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 363/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 3.5678 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 364/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.5807 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 365/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 3.6010 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 366/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.5894 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 367/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.5908 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 368/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.6129 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 369/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.6043 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 370/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.6233 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 371/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9950 - val_loss: 3.6409 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 372/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 3.6561 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 373/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.6494 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 374/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 3.6571 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 375/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.6643 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 376/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.6538 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 377/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.6907 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 378/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 3.6939 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 379/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.6950 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 380/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.7008 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 381/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.6996 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 382/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.7526 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 383/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.7491 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 384/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.7523 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 385/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.7401 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 386/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.7343 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 387/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 3.7100 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 388/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 3.7633 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 389/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.7775 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 390/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.7921 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 391/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.7652 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 392/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.7578 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 393/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.8098 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 394/1500\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.99 - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.7354 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 395/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.7253 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 396/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 3.7206 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 397/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.7478 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 398/1500\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.99 - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.7364 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 399/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 3.7527 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 400/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 3.7500 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 401/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 3.7911 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 402/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 3.8525 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 403/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 3.7921 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 404/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.7643 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 405/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9954 - val_loss: 3.7649 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 406/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 3.7654 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 407/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.7757 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 408/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.8047 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 409/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 3.8135 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 410/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.8036 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 411/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 3.8066 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 412/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9954 - val_loss: 3.8050 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 413/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.8198 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 414/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.8311 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 415/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 3.8626 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 416/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.9127 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 417/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 3.8827 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 418/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.8756 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 419/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.8814 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 420/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9950 - val_loss: 3.8713 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 421/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.8716 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 422/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.9017 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 423/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 3.9522 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 424/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.9481 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 425/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.9831 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 426/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.9680 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 427/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.9404 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 428/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.9421 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 429/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 3.9534 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 430/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.9645 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 431/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 3.9689 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 432/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.9601 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 433/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.9683 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 434/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 3.9758 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 435/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.9839 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 436/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.9913 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 437/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 3.9965 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 438/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 3.9897 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 439/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.0134 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 440/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.0231 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 441/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 4.0159 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 442/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.0439 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 443/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 4.0317 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 444/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 4.0549 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 445/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.0416 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 446/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 4.0461 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 447/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 4.0480 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 448/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 3.9994 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 449/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.0058 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 450/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.0433 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 451/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.0385 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 452/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9954 - val_loss: 4.0449 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 453/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.0582 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 454/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.0910 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 455/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.1611 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 456/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.1086 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 457/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.1090 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 458/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.0992 - val_accuracy: 0.4815 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 4.1344 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 460/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.1171 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 461/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.1173 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 462/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.1619 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 463/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.1418 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 464/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 4.1442 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 465/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 4.1067 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 466/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.0862 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 467/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.1197 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 468/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.1310 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 469/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.1396 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 470/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.3115 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 471/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.2834 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 472/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9954 - val_loss: 4.2613 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 473/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.2361 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 474/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.1746 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 475/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.1855 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 476/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 4.1623 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 477/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 4.1646 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 478/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.1617 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 479/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.1777 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 480/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.1920 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 481/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.2139 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 482/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.2536 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 483/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 4.1844 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 484/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 4.0996 - val_accuracy: 0.4719 - lr: 1.0000e-04\n",
      "Epoch 485/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.2370 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 486/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.2651 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 487/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.2791 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 488/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.2299 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 489/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 4.2236 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 490/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 4.2398 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 491/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.2705 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 492/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 4.2816 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 493/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 4.2728 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 494/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.2592 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 495/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.3134 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 496/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 4.3822 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 497/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 4.5150 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 498/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 4.5384 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 499/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 4.4484 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 500/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.4610 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 501/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 4.4279 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 502/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.4234 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 503/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 4.4384 - val_accuracy: 0.4687 - lr: 1.0000e-04\n",
      "Epoch 504/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.4140 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 505/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.4060 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 506/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.4234 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 507/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.4347 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 508/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.4468 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 509/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.4485 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 510/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.4565 - val_accuracy: 0.4719 - lr: 1.0000e-04\n",
      "Epoch 511/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.4876 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 512/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 4.4561 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 513/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.5616 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 514/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 4.5155 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 515/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5687 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 516/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6442 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 517/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.6186 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 518/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 4.5699 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 519/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5592 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 520/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.5882 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 521/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5559 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 522/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5254 - val_accuracy: 0.4719 - lr: 1.0000e-04\n",
      "Epoch 523/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 4.5437 - val_accuracy: 0.4703 - lr: 1.0000e-04\n",
      "Epoch 524/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5619 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 525/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5685 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 526/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5543 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 527/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5731 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 528/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5374 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 529/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6060 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 530/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5764 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 531/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.6000 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 532/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5800 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 533/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5801 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 534/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 4.5992 - val_accuracy: 0.4703 - lr: 1.0000e-04\n",
      "Epoch 535/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.5675 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 536/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5605 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 537/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 4.5893 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 538/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 4.5916 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 539/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5497 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 540/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5757 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 541/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5938 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 542/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 4.5995 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 543/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6031 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 544/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.6582 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 545/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 4.6227 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 546/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.6327 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 547/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9973 - val_loss: 4.8790 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 548/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0163 - accuracy: 0.9924 - val_loss: 5.6260 - val_accuracy: 0.5056 - lr: 1.0000e-04\n",
      "Epoch 549/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0056 - accuracy: 0.9954 - val_loss: 4.8300 - val_accuracy: 0.4976 - lr: 1.0000e-04\n",
      "Epoch 550/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0044 - accuracy: 0.9966 - val_loss: 4.8995 - val_accuracy: 0.5024 - lr: 1.0000e-04\n",
      "Epoch 551/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 4.8209 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 552/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 4.7392 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 553/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9977 - val_loss: 4.5752 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 554/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9973 - val_loss: 4.5692 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 555/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 4.5617 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 556/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5593 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 557/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5616 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 558/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9981 - val_loss: 4.5495 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 559/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5546 - val_accuracy: 0.4848 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 4.5549 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 561/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5499 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 562/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 4.5523 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 563/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5475 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 564/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5428 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 565/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5443 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 566/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5454 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 567/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5481 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 568/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5509 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 569/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 4.5538 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 570/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5522 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 571/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5565 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 572/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5556 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 573/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5670 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 574/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5672 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 575/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 4.5651 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 576/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5630 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 577/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5598 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 578/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5594 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 579/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5574 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 580/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5609 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 581/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5646 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 582/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5617 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 583/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5607 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 584/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5622 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 585/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 4.5605 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 586/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5595 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 587/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 4.5600 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 588/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 4.5607 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 589/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5589 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 590/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 4.5593 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 591/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 4.5609 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 592/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 4.5627 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 593/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5642 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 594/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5637 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 595/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5629 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 596/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5664 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 597/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5680 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 598/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5672 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 599/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5701 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 600/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5691 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 601/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5764 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 602/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5750 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 603/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5742 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 604/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 4.5761 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 605/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5753 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 606/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5754 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 607/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5786 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 608/1500\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.99 - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5818 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 609/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5863 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 610/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5846 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 611/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.5856 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 612/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5804 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 613/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.5787 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 614/1500\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5790 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 615/1500\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5797 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 616/1500\n",
      "41/41 [==============================] - 7s 172ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5817 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 617/1500\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 4.5833 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 618/1500\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 4.5817 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 619/1500\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5826 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 620/1500\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5848 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 621/1500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5845 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 622/1500\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.5853 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 623/1500\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5860 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 624/1500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5848 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 625/1500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5772 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 626/1500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5755 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 627/1500\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5765 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 628/1500\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 4.5775 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 629/1500\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.0037 - accuracy: 0.9950 - val_loss: 4.5817 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 630/1500\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5810 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 631/1500\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5807 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 632/1500\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5848 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 633/1500\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5795 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 634/1500\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5813 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 635/1500\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5850 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 636/1500\n",
      "41/41 [==============================] - 1s 33ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.5863 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 637/1500\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5877 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 638/1500\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5894 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 639/1500\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5871 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 640/1500\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5898 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 641/1500\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5900 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 642/1500\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 4.5885 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 643/1500\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5883 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 644/1500\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5903 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 645/1500\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5946 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 646/1500\n",
      "41/41 [==============================] - 1s 33ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5968 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 647/1500\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5936 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 648/1500\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5931 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 649/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5942 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 650/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.5965 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 651/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.5973 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 652/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.5990 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 653/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 4.6006 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 654/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6000 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 655/1500\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6016 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 656/1500\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6043 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 657/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6037 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 658/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.6056 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 659/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 4.6053 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 660/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.6026 - val_accuracy: 0.4848 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6001 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 662/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.6035 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 663/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.6049 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 664/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6056 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 665/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.6055 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 666/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6075 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 667/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6097 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 668/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 4.6108 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 669/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 4.6082 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 670/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6048 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 671/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6098 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 672/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6136 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 673/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6185 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 674/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.7201 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 675/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6970 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 676/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6929 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 677/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.6776 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 678/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 4.6739 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 679/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6657 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 680/1500\n",
      "41/41 [==============================] - 1s 34ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6689 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 681/1500\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 4.6672 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 682/1500\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.6643 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 683/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6589 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 684/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6615 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 685/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6491 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 686/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.6538 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 687/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6534 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 688/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6514 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 689/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6509 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 690/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.6534 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 691/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6479 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 692/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 4.6495 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 693/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6493 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 694/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6503 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 695/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6490 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 696/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6507 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 697/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6508 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 698/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6538 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 699/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6540 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 700/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6529 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 701/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.6535 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 702/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6559 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 703/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6556 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 704/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6556 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 705/1500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6564 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 706/1500\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6529 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 707/1500\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6563 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 708/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.6666 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 709/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6651 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 710/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6624 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 711/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6579 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 712/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 4.6520 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 713/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6506 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 714/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6504 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 715/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.6517 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 716/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.6632 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 717/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6622 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 718/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.6653 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 719/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6538 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 720/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6659 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 721/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6666 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 722/1500\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.6723 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 723/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.6580 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 724/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6631 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 725/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 4.6656 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 726/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6661 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 727/1500\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6731 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 728/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6653 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 729/1500\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6720 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 730/1500\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6752 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 731/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6683 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 732/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 4.6745 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 733/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6726 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 734/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 4.6622 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 735/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6756 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 736/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6727 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 737/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6820 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 738/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6803 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 739/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6792 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 740/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6731 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 741/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.6658 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 742/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6814 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 743/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.6861 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 744/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 4.6844 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 745/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6846 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 746/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6894 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 747/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6862 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 748/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.6855 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 749/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6834 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 750/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6875 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 751/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6824 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 752/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6823 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 753/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6844 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 754/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.6878 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 755/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6893 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 756/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6959 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 757/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6670 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 758/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.6813 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 759/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.6806 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 760/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.6867 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 761/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.7001 - val_accuracy: 0.4783 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 762/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6917 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 763/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.6916 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 764/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 4.7003 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 765/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7162 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 766/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.6921 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 767/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.6955 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 768/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 4.7173 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 769/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.6978 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 770/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.7066 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 771/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.7062 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 772/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.7113 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 773/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 4.7089 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 774/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.7100 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 775/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 4.7249 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 776/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.7269 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 777/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.7274 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 778/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7309 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 779/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.7208 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 780/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7197 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 781/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.7343 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 782/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.7297 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 783/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.7537 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 784/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7531 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 785/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.7449 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 786/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7488 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 787/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.7460 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 788/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.7410 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 789/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7388 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 790/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7385 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 791/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.7368 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 792/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.7481 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 793/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.7267 - val_accuracy: 0.4976 - lr: 1.0000e-04\n",
      "Epoch 794/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.7432 - val_accuracy: 0.4992 - lr: 1.0000e-04\n",
      "Epoch 795/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.7311 - val_accuracy: 0.5008 - lr: 1.0000e-04\n",
      "Epoch 796/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.7255 - val_accuracy: 0.5040 - lr: 1.0000e-04\n",
      "Epoch 797/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.7204 - val_accuracy: 0.4960 - lr: 1.0000e-04\n",
      "Epoch 798/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.7558 - val_accuracy: 0.4960 - lr: 1.0000e-04\n",
      "Epoch 799/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7540 - val_accuracy: 0.4960 - lr: 1.0000e-04\n",
      "Epoch 800/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.7455 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 801/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.7514 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 802/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.7546 - val_accuracy: 0.4976 - lr: 1.0000e-04\n",
      "Epoch 803/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.7649 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 804/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7803 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 805/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 4.7644 - val_accuracy: 0.4992 - lr: 1.0000e-04\n",
      "Epoch 806/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.7587 - val_accuracy: 0.4960 - lr: 1.0000e-04\n",
      "Epoch 807/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7548 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 808/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 4.7628 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 809/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.7596 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 810/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 4.7566 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 811/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.7539 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 812/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.7481 - val_accuracy: 0.4976 - lr: 1.0000e-04\n",
      "Epoch 813/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.7588 - val_accuracy: 0.4976 - lr: 1.0000e-04\n",
      "Epoch 814/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7658 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 815/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7704 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 816/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.7769 - val_accuracy: 0.4960 - lr: 1.0000e-04\n",
      "Epoch 817/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.7801 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 818/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.7905 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 819/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 4.7898 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 820/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7906 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 821/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.7955 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 822/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.7919 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 823/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7902 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 824/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.7931 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 825/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.7853 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 826/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.8118 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 827/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.8362 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 828/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.8229 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 829/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.8194 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 830/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.8229 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 831/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.8256 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 832/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.8201 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 833/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.8280 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 834/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.8404 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 835/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.8247 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 836/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.8382 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 837/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.8411 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 838/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.8382 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 839/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 4.8582 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 840/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.8537 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 841/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 4.8594 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 842/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 4.8674 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 843/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.8656 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 844/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.8723 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 845/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0153 - val_accuracy: 0.4976 - lr: 1.0000e-04\n",
      "Epoch 846/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.9616 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 847/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.9599 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 848/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.9382 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 849/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.9111 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 850/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.9227 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 851/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.1124 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 852/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.0333 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 853/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.9925 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 854/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.0456 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 855/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.9833 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 856/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.9598 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 857/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.9528 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 858/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.9710 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 859/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.9362 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 860/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.9669 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 861/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.9736 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 862/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.9843 - val_accuracy: 0.4735 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 863/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.9740 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 864/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.9987 - val_accuracy: 0.4976 - lr: 1.0000e-04\n",
      "Epoch 865/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.9759 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 866/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 4.9736 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 867/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9950 - val_loss: 4.9961 - val_accuracy: 0.4719 - lr: 1.0000e-04\n",
      "Epoch 868/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.9916 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 869/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 4.9908 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 870/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 4.9871 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 871/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.9844 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 872/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0146 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 873/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.9900 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 874/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 5.0035 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 875/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0072 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 876/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0062 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 877/1500\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.99 - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 4.9935 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 878/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0025 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 879/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 4.9933 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 880/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 4.9630 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 881/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0356 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 882/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.1813 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 883/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.1066 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 884/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.0684 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 885/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.0693 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 886/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.0624 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 887/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.0561 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 888/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.0446 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 889/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0265 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 890/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.0441 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 891/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.0851 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 892/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0540 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 893/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0555 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 894/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.0687 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 895/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.0664 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 896/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9977 - val_loss: 5.1822 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 897/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.1795 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 898/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.2093 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 899/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.1471 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 900/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.1698 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 901/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.1734 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 902/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.1593 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 903/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.1567 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 904/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.1735 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 905/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.1471 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 906/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9962 - val_loss: 6.2731 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 907/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 5.2402 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 908/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0057 - accuracy: 0.9962 - val_loss: 4.7631 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 909/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0061 - accuracy: 0.9962 - val_loss: 5.2340 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 910/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0069 - accuracy: 0.9966 - val_loss: 5.6797 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 911/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 5.6198 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 912/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0043 - accuracy: 0.9969 - val_loss: 5.5323 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 913/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.4540 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 914/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.4191 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 915/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.3910 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 916/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.3904 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 917/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0039 - accuracy: 0.9973 - val_loss: 5.3755 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 918/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.3706 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 919/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.3579 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 920/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3616 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 921/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3573 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 922/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3539 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 923/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3554 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 924/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3515 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 925/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.3573 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 926/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.3460 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 927/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3352 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 928/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3362 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 929/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3455 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 930/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3534 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 931/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3507 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 932/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3519 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 933/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9981 - val_loss: 5.3579 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 934/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3472 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 935/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0042 - accuracy: 0.9969 - val_loss: 5.7367 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 936/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0047 - accuracy: 0.9966 - val_loss: 5.4389 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 937/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0097 - accuracy: 0.9954 - val_loss: 5.6769 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 938/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0049 - accuracy: 0.9969 - val_loss: 5.1748 - val_accuracy: 0.5104 - lr: 1.0000e-04\n",
      "Epoch 939/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.1402 - val_accuracy: 0.5040 - lr: 1.0000e-04\n",
      "Epoch 940/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.1172 - val_accuracy: 0.5040 - lr: 1.0000e-04\n",
      "Epoch 941/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.0961 - val_accuracy: 0.4992 - lr: 1.0000e-04\n",
      "Epoch 942/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0772 - val_accuracy: 0.5008 - lr: 1.0000e-04\n",
      "Epoch 943/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.0826 - val_accuracy: 0.5008 - lr: 1.0000e-04\n",
      "Epoch 944/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.0699 - val_accuracy: 0.4992 - lr: 1.0000e-04\n",
      "Epoch 945/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.0582 - val_accuracy: 0.4992 - lr: 1.0000e-04\n",
      "Epoch 946/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.0210 - val_accuracy: 0.5040 - lr: 1.0000e-04\n",
      "Epoch 947/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0259 - val_accuracy: 0.5024 - lr: 1.0000e-04\n",
      "Epoch 948/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0259 - val_accuracy: 0.5024 - lr: 1.0000e-04\n",
      "Epoch 949/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.0262 - val_accuracy: 0.4992 - lr: 1.0000e-04\n",
      "Epoch 950/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0313 - val_accuracy: 0.4992 - lr: 1.0000e-04\n",
      "Epoch 951/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.0312 - val_accuracy: 0.4960 - lr: 1.0000e-04\n",
      "Epoch 952/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.0366 - val_accuracy: 0.4976 - lr: 1.0000e-04\n",
      "Epoch 953/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.0337 - val_accuracy: 0.5008 - lr: 1.0000e-04\n",
      "Epoch 954/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0349 - val_accuracy: 0.4992 - lr: 1.0000e-04\n",
      "Epoch 955/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.0412 - val_accuracy: 0.5024 - lr: 1.0000e-04\n",
      "Epoch 956/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 5.0456 - val_accuracy: 0.5008 - lr: 1.0000e-04\n",
      "Epoch 957/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0455 - val_accuracy: 0.5008 - lr: 1.0000e-04\n",
      "Epoch 958/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0439 - val_accuracy: 0.5008 - lr: 1.0000e-04\n",
      "Epoch 959/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.0359 - val_accuracy: 0.4992 - lr: 1.0000e-04\n",
      "Epoch 960/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9981 - val_loss: 5.0395 - val_accuracy: 0.5008 - lr: 1.0000e-04\n",
      "Epoch 961/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.0430 - val_accuracy: 0.5008 - lr: 1.0000e-04\n",
      "Epoch 962/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0420 - val_accuracy: 0.5008 - lr: 1.0000e-04\n",
      "Epoch 963/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.0341 - val_accuracy: 0.4896 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 964/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0376 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 965/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.0381 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 966/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0392 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 967/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0418 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 968/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0440 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 969/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9981 - val_loss: 5.0464 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 970/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0539 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 971/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9981 - val_loss: 5.0533 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 972/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0502 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 973/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0523 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 974/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.0500 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 975/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0543 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 976/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0539 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 977/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0619 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 978/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0644 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 979/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.0609 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 980/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0615 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 981/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0607 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 982/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0696 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 983/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0704 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 984/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.0718 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 985/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.0685 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 986/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0728 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 987/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.0686 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 988/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.1620 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 989/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.1482 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 990/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.1191 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 991/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0915 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 992/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.0855 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 993/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0823 - val_accuracy: 0.4976 - lr: 1.0000e-04\n",
      "Epoch 994/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0837 - val_accuracy: 0.4960 - lr: 1.0000e-04\n",
      "Epoch 995/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.0874 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 996/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.0860 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 997/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0882 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 998/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.0857 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 999/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.0883 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 1000/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.0882 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 1001/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9977 - val_loss: 5.0861 - val_accuracy: 0.4960 - lr: 1.0000e-04\n",
      "Epoch 1002/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.0932 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 1003/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.0992 - val_accuracy: 0.4960 - lr: 1.0000e-04\n",
      "Epoch 1004/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.1058 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 1005/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.1100 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 1006/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.1082 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 1007/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.1094 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 1008/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.1076 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 1009/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.1092 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 1010/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.1116 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 1011/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.1110 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 1012/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.1148 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 1013/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.1133 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 1014/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.1128 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 1015/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.1174 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 1016/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.1131 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 1017/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.1065 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 1018/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.1077 - val_accuracy: 0.4944 - lr: 1.0000e-04\n",
      "Epoch 1019/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.1113 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Epoch 1020/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.1209 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 1021/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0070 - accuracy: 0.9943 - val_loss: 5.5329 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 1022/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0073 - accuracy: 0.9962 - val_loss: 5.9543 - val_accuracy: 0.5152 - lr: 1.0000e-04\n",
      "Epoch 1023/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0045 - accuracy: 0.9966 - val_loss: 5.7331 - val_accuracy: 0.4992 - lr: 1.0000e-04\n",
      "Epoch 1024/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0048 - accuracy: 0.9966 - val_loss: 5.4176 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1025/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0039 - accuracy: 0.9973 - val_loss: 5.4430 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1026/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.4337 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1027/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0039 - accuracy: 0.9973 - val_loss: 5.3574 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1028/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.3975 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1029/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.4096 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1030/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4082 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1031/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4107 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1032/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4127 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1033/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4054 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1034/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4046 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1035/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3892 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1036/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3914 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1037/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3914 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1038/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3967 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1039/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3944 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1040/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3847 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1041/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3888 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1042/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3887 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1043/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3856 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1044/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3855 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1045/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3819 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1046/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3719 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1047/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3785 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1048/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3816 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1049/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.3814 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1050/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.3768 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1051/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3760 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1052/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.3845 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1053/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3866 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1054/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3872 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1055/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.3901 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1056/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.3867 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1057/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3843 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1058/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3853 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1059/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9977 - val_loss: 5.3783 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1060/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3821 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1061/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3840 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1062/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3858 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1063/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3911 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1064/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3895 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1065/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.3947 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1066/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3892 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1067/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3828 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1068/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3829 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1069/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3761 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1070/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.3761 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1071/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3713 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1072/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.3685 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1073/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3678 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1074/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3664 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1075/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3634 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1076/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3785 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1077/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 5.3754 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1078/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.3691 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1079/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3698 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1080/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3745 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1081/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3658 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1082/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3696 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1083/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 5.3701 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1084/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3674 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1085/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.3746 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1086/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.3756 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1087/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.3719 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1088/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3723 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1089/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3736 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1090/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3733 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1091/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.3700 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1092/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3694 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1093/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9981 - val_loss: 5.3688 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1094/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3701 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1095/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3749 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1096/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3748 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1097/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3734 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1098/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 5.3753 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1099/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3735 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1100/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3756 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1101/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3727 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1102/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3754 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1103/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3806 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1104/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3813 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1105/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.3824 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1106/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3792 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1107/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3705 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1108/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3663 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1109/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3716 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1110/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3724 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1111/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.3752 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1112/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3723 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1113/1500\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.3763 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1114/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3783 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1115/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.3781 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1116/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3784 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1117/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3787 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1118/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.3760 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1119/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3881 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1120/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3873 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1121/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3802 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1122/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3859 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1123/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.3904 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1124/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3855 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1125/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.3849 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1126/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3869 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1127/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3984 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1128/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3936 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1129/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3932 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1130/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3940 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1131/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3911 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1132/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3891 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1133/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.3862 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1134/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.3839 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1135/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3848 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1136/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.3865 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1137/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3855 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1138/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3852 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1139/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3874 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1140/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3890 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1141/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.3949 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1142/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.3996 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1143/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3985 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1144/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3951 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1145/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.3972 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1146/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4048 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1147/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4026 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1148/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3997 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1149/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3988 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1150/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3921 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1151/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3937 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1152/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3952 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1153/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3975 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1154/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4018 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1155/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 5.4016 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1156/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3990 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1157/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3995 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1158/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3993 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1159/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3966 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1160/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3988 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1161/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3996 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1162/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3999 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1163/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3979 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1164/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3960 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1165/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3961 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1166/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3986 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1167/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3926 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1168/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3884 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1169/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.3837 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1170/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3835 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1171/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3896 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1172/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3906 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1173/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 5.3945 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1174/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3945 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1175/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3957 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1176/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3964 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1177/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3965 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1178/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.3963 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1179/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4190 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1180/1500\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.99 - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 5.4091 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1181/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4068 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1182/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4105 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1183/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4164 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1184/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9950 - val_loss: 5.4172 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1185/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4124 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1186/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4133 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1187/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4203 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1188/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 5.4162 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1189/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.4119 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1190/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4129 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1191/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4116 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1192/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.4131 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1193/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4088 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1194/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3992 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1195/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4000 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1196/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3972 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1197/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4069 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1198/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4101 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1199/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4116 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1200/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4019 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1201/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3988 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1202/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4028 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1203/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4030 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1204/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4070 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1205/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4023 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1206/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4181 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1207/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.4093 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1208/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4096 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1209/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9977 - val_loss: 5.3781 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1210/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.3964 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1211/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.3988 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1212/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.3783 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1213/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4057 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1214/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.4471 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1215/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4495 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1216/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4386 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1217/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4299 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1218/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4229 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1219/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4266 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1220/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4317 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1221/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4239 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1222/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4144 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1223/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4193 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1224/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4327 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1225/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4271 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1226/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4272 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1227/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3868 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1228/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.3852 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1229/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4014 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1230/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4189 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 1231/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4199 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1232/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4336 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1233/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4343 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1234/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4427 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1235/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4395 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1236/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4339 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1237/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4366 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1238/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4512 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1239/1500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4603 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1240/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4615 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1241/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4480 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1242/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4440 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1243/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4426 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1244/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4404 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1245/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4502 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1246/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4457 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1247/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.4531 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1248/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4518 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1249/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4518 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1250/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4405 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1251/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4501 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1252/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4699 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1253/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4519 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1254/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.4520 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1255/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4485 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1256/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4512 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1257/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4518 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1258/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4606 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1259/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4819 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1260/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4789 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1261/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4754 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1262/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.4687 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1263/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4621 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1264/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4734 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1265/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4583 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1266/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.5012 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1267/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4922 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1268/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4819 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1269/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4859 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1270/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4826 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1271/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4734 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1272/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4814 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1273/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.4923 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1274/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4964 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1275/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.5199 - val_accuracy: 0.4719 - lr: 1.0000e-04\n",
      "Epoch 1276/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.5045 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1277/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.4904 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1278/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4957 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1279/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.4972 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1280/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4778 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1281/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4929 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1282/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4947 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1283/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.5025 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1284/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4972 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1285/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4943 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1286/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.5373 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 1287/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4977 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1288/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4904 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 1289/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4858 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1290/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4889 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1291/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.5038 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1292/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.4958 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1293/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.4982 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1294/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4939 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1295/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.4952 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1296/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.5010 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1297/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.5010 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1298/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.5245 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1299/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.5236 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1300/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.5297 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1301/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.5098 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1302/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.5101 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1303/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.4926 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1304/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.5102 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1305/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.5114 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1306/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.5036 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1307/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.5234 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1308/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.5327 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1309/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.5639 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1310/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.6068 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 1311/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.5826 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1312/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 5.5741 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1313/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.5588 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1314/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.5910 - val_accuracy: 0.4719 - lr: 1.0000e-04\n",
      "Epoch 1315/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.5877 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1316/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.5769 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1317/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.5824 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1318/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.5806 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1319/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.5594 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1320/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.5720 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1321/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.5821 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1322/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.5701 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1323/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.5674 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 1324/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.5957 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1325/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 5.6786 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1326/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.6421 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1327/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.6105 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1328/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.5885 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1329/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.6186 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1330/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.6733 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1331/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.6932 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1332/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.6314 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1333/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.6149 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1334/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.5894 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1335/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.6406 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1336/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.6054 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 1337/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.5627 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 1338/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.6191 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1339/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.6030 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1340/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.6063 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 1341/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.6150 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1342/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.8139 - val_accuracy: 0.4575 - lr: 1.0000e-04\n",
      "Epoch 1343/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.6472 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1344/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.6286 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1345/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.6507 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1346/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.6675 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1347/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.6976 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1348/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7111 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1349/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7068 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1350/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7330 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1351/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.7271 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1352/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7182 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1353/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.7347 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1354/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.7203 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1355/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7152 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1356/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7648 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1357/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7205 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1358/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.7178 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1359/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.7137 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1360/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.7415 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1361/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7171 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1362/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7153 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1363/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.7200 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1364/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7179 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1365/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7241 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1366/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7766 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1367/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7524 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1368/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7844 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1369/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.8116 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1370/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.9026 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1371/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.9582 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 1372/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.8969 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 1373/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.8311 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1374/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.8523 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1375/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.8527 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 1376/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.8125 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1377/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.8126 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1378/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.8393 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 1379/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 6.0264 - val_accuracy: 0.4703 - lr: 1.0000e-04\n",
      "Epoch 1380/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.9309 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 1381/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.9338 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1382/1500\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 5.8841 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 1383/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9954 - val_loss: 5.8870 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1384/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.8460 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1385/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.8507 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1386/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.8453 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 1387/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.8285 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1388/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 6.1769 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1389/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 6.1101 - val_accuracy: 0.4976 - lr: 1.0000e-04\n",
      "Epoch 1390/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0063 - accuracy: 0.9966 - val_loss: 6.2827 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1391/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0039 - accuracy: 0.9973 - val_loss: 6.1283 - val_accuracy: 0.4719 - lr: 1.0000e-04\n",
      "Epoch 1392/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 5.9862 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 1393/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0039 - accuracy: 0.9973 - val_loss: 5.8722 - val_accuracy: 0.4848 - lr: 1.0000e-04\n",
      "Epoch 1394/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7945 - val_accuracy: 0.4880 - lr: 1.0000e-04\n",
      "Epoch 1395/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 5.8642 - val_accuracy: 0.4864 - lr: 1.0000e-04\n",
      "Epoch 1396/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0046 - accuracy: 0.9966 - val_loss: 5.8078 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1397/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.7944 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1398/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9962 - val_loss: 5.8216 - val_accuracy: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 1399/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.8160 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1400/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7964 - val_accuracy: 0.4703 - lr: 1.0000e-04\n",
      "Epoch 1401/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7957 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1402/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.7837 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1403/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7738 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1404/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7756 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1405/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 5.7514 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1406/1500\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 5.7454 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1407/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7408 - val_accuracy: 0.4783 - lr: 1.0000e-04\n",
      "Epoch 1408/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7457 - val_accuracy: 0.4767 - lr: 1.0000e-04\n",
      "Epoch 1409/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9977 - val_loss: 5.7408 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 1410/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9977 - val_loss: 5.7062 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1411/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.6976 - val_accuracy: 0.4623 - lr: 1.0000e-04\n",
      "Epoch 1412/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7063 - val_accuracy: 0.4607 - lr: 1.0000e-04\n",
      "Epoch 1413/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7135 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1414/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7233 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1415/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7304 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1416/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 5.7340 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1417/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7399 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1418/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9981 - val_loss: 5.7612 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1419/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7521 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1420/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7499 - val_accuracy: 0.4639 - lr: 1.0000e-04\n",
      "Epoch 1421/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7493 - val_accuracy: 0.4639 - lr: 1.0000e-04\n",
      "Epoch 1422/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7458 - val_accuracy: 0.4639 - lr: 1.0000e-04\n",
      "Epoch 1423/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7414 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1424/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7404 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1425/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7442 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1426/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7459 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1427/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7470 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1428/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7465 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1429/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7446 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1430/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7457 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1431/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7465 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1432/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7476 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1433/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7488 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1434/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7476 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1435/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.7475 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1436/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 5.7488 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1437/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 5.7524 - val_accuracy: 0.4639 - lr: 1.0000e-04\n",
      "Epoch 1438/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7715 - val_accuracy: 0.4687 - lr: 1.0000e-04\n",
      "Epoch 1439/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7723 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1440/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7692 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1441/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.7573 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1442/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7628 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1443/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7632 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1444/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7656 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1445/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7653 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1446/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7675 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1447/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7681 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1448/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7692 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1449/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7689 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1450/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7697 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1451/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7744 - val_accuracy: 0.4639 - lr: 1.0000e-04\n",
      "Epoch 1452/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7760 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1453/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9981 - val_loss: 5.7746 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1454/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7709 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1455/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7736 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1456/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.7716 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1457/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7677 - val_accuracy: 0.4639 - lr: 1.0000e-04\n",
      "Epoch 1458/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7674 - val_accuracy: 0.4623 - lr: 1.0000e-04\n",
      "Epoch 1459/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7691 - val_accuracy: 0.4623 - lr: 1.0000e-04\n",
      "Epoch 1460/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7658 - val_accuracy: 0.4623 - lr: 1.0000e-04\n",
      "Epoch 1461/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7659 - val_accuracy: 0.4623 - lr: 1.0000e-04\n",
      "Epoch 1462/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.7651 - val_accuracy: 0.4639 - lr: 1.0000e-04\n",
      "Epoch 1463/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7651 - val_accuracy: 0.4623 - lr: 1.0000e-04\n",
      "Epoch 1464/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7667 - val_accuracy: 0.4623 - lr: 1.0000e-04\n",
      "Epoch 1465/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7669 - val_accuracy: 0.4623 - lr: 1.0000e-04\n",
      "Epoch 1466/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7677 - val_accuracy: 0.4607 - lr: 1.0000e-04\n",
      "Epoch 1467/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.7615 - val_accuracy: 0.4607 - lr: 1.0000e-04\n",
      "Epoch 1468/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7661 - val_accuracy: 0.4623 - lr: 1.0000e-04\n",
      "Epoch 1469/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7669 - val_accuracy: 0.4607 - lr: 1.0000e-04\n",
      "Epoch 1470/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.7665 - val_accuracy: 0.4591 - lr: 1.0000e-04\n",
      "Epoch 1471/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7631 - val_accuracy: 0.4639 - lr: 1.0000e-04\n",
      "Epoch 1472/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.7629 - val_accuracy: 0.4639 - lr: 1.0000e-04\n",
      "Epoch 1473/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.7581 - val_accuracy: 0.4639 - lr: 1.0000e-04\n",
      "Epoch 1474/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7565 - val_accuracy: 0.4639 - lr: 1.0000e-04\n",
      "Epoch 1475/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7514 - val_accuracy: 0.4639 - lr: 1.0000e-04\n",
      "Epoch 1476/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7656 - val_accuracy: 0.4687 - lr: 1.0000e-04\n",
      "Epoch 1477/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.7639 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1478/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7630 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1479/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7610 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1480/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.7610 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1481/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7619 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1482/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9981 - val_loss: 5.7590 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1483/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7551 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1484/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7571 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1485/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.7575 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1486/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7589 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1487/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7553 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1488/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 5.7601 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1489/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7593 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1490/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7595 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1491/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.7584 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1492/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 5.7607 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1493/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - accuracy: 0.9966 - val_loss: 5.7628 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1494/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7647 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1495/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9958 - val_loss: 5.7621 - val_accuracy: 0.4687 - lr: 1.0000e-04\n",
      "Epoch 1496/1500\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 5.7627 - val_accuracy: 0.4687 - lr: 1.0000e-04\n",
      "Epoch 1497/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7653 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1498/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 5.7669 - val_accuracy: 0.4671 - lr: 1.0000e-04\n",
      "Epoch 1499/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9969 - val_loss: 5.7694 - val_accuracy: 0.4655 - lr: 1.0000e-04\n",
      "Epoch 1500/1500\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 5.7690 - val_accuracy: 0.4639 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "hist = inception.fit(X_train_tr, y_train_ohe, X_test_tr, y_test_ohe, y_train, plot_test_acc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5yUdd3/8ddnZk/Act4FkUUBBRVUTNE8nyhDS9GywrLMSm/z511a3WlqZdnB0rqzLInbzGOSeaTyUKZJeUpQFEFQRJEFgeW0sCx7mJnv74/vzO7M7OzuzOwsu9f0fj4e+5i9rrkOnzlcn+t7fa7vdY055xARkeAL9XUAIiJSGEroIiJFQgldRKRIKKGLiBQJJXQRkSJR0lcrrqqqcuPHj++r1YuIBNKiRYs2OeeqMz3XZwl9/PjxLFy4sK9WLyISSGa2urPnVHIRESkSSugiIkVCCV1EpEgooYuIFAkldBGRItFtQjezW81so5m91snzZma/MLOVZvaqmR1a+DBFRKQ72bTQbwNmdvH8qcCk+N+FwM09D0tERHLVbT9059wCMxvfxSSzgDucvw/v82Y2zMzGOOfeK1CMOYvGHOGQtQ1HojGizhEyozQcojUaIxpzlIVDxJyjJBwiEo1REn+uND7sgNKw3+c1R6KUl4Tblr9hexPVg8tpaIoQChkDSsOUlWTeP0ZjDud8TM0Rv+5B5f6tX7OlkZrhAzDz8TrnaInGMIxtjS2MrCwHIBwyGlsilIVDlIRDOOdoao1RGjZKwiF2Nkfalgm0vY5E7GXhkI8j/pqcc7RGfUwx5ygJGZGYw6Bt+dGYf28AWiKxjK9vV0uUAWXhDu99cyRKaci/v2aGc37d0ZijbkczG3c0M7FqEA3NEaoqywmFwDAWrt7CiEFl7L/HEOp2NFNeGmJIRSlrtjQybsRAnHMpcSZ/xmbW9rlHojHeq2+iZvgAarfuYszQirbPORyytvc70+cEEHPgcJSEQhi0fX+Sv1c7mlqpLC/x0yZ9j8Iha3sfEutpaI5QUeI/u1jMryMaf48rSsM0tUbZ0RRh6IBSykpCNDRHaInEiERjNEdirNu2i/33GILD4RyUlYTY2tjCtsZWyktCLFlbz6kHjsHMf1fqd7WyenMjAJNGV7JpRzPjRgwkGnM0t8ZojcUg/l2IRGOs2bqLaMwxYlAZewyp8K+tooTScIjVm3dSXhJmR1OECVWDWFe/i7HDBlC/q5UhFaUsWVvPwTVDCYeMDdubKAuHGDWkou1zKIl/90JG/NFI3LQ75vxnWbt1F3sMraCiNNw2D0BjS6Rtu32vfhcjBpURMmub7r36JkYPqaA5EmVQWQlmsLUx8bn497YlEmNnc4TWWIxRgytoao1i8VgGlpWkbC9NrVFKwyHCIaMlEiMW3x4fXryOyaMq2XPYALY1trLvqMq27aGhKUJpidHUGuPld7dyyLhhbd+fkBnr65uo29HMXiMHMrFqEGu27KJqcFnbugupEEscC6xJGq6Nj+uQ0M3sQnwrnr322qtHK21sifD5215k7bZdlIZDrKrbyeCKEnY0RQAYOaiMzTtbGFAaZldrtG2+mz71Pi75/cs9WndvmL73cBqaI6zYsIOe3KI+kUy6MnxgKQ3NEVqjmacLh4yRg8rYuKM5/0ACojRsnb4P+Ro2sJRtja0FXWY2vnrvK7t9nb1l7LABrN22a7esa68RA3l3S+NuWVfC54+ZwLdPn1Lw5RYioXds6kDGLcQ5NxeYCzB9+vQebUWPLlnP86u2pIwbOaisLaFv3tnix1WWUbu1/Ytx9/Pv9mS1HZjRIQEnkmpleQkNzZEO8+w7qpLK8hK272pl1aadACxcvbUg8SSSeUVpiKbWWNv4qXsOYem67YBvwXS3jFyTeVVlGeUl4ZSNcNTg8i6Xc8FxE5j/yjqaWmPU72qPaeywAQDUNTTTEol1NjvDB5YSiTp2ZHiP04XMt7rTJSfzgWVhGluiHSfKclkJnSXz9J3twTVDebW2vsN0ZeEQnzi8htGDK9jU0My7WxpZuHorO5oifPigMTRHYixfv50Rg8pS5t93VCWRaIx3NnednCZUDeLzx4ynbodf9sjKcp5+o44Z+4/i6TfqWL5+ByftV81TK+o6zDuoLMzOlihlJaFOP5vJoytZVbeTSDcNi2R7Dq1gXX1T25Fiealv/VYPLqcui+/icZOq+OebmygJGQPLwmxvav9OJH+uVZVlbGpoSZl3YFmYSaMqGTt8AK/W1rNlZ+rz+40eTF1DMydMrmbzzhb+9WYdMQfH7DsSw6jb0UxJ2BhUVsLLa7ZSFg4xemgFq+p2Zox1/MiBnH/M+Kzfm1wUIqHXAuOShmuAdQVYbpdWbWogHDJWXDuTkBlR59pKDE2tUSpKwynTP/bae1x010vUNTQzfuRAnvzaidQ1NDNiUBkl8UPj1misw6E8QH1jK5FYrK38Af4QuzkSaztcTl9fQkvEH4Lvao1SWV7S5bTJ87y7pZF9R1XS1BqlvCTUlkASh/zJsdY3ttIai1FZXtJh2W9v2sn4kQMzlhiaWqOEzCgJGW9v3sk+1ZUdponFXFtZCnyyNyAUjyOb15N4Tf98s44v3L6Q351/OCftNwqAqz6cWytl444mykvCDB1QmtN83cUGZCwpxWLxEpjRVnJLl/iMWqMuZRmJeZPfn+ZIlLVbdzExw3vdnWzf6860RmPc8+93+cT0cR2W86344zdPO6BtXOK7m1xmynV9pWnbUku8fDRmWEWn72eh5Pt+NbZEWFJbT3MkxvGTM94ypd8qREKfD1xiZvOA9wP1u6N+vrWxlWEDStsSTSjpQCHzh+iff2/bLg6qGUooZIyO1/kS0r98CUMHdkweFq/jdb4+L7GBV8br29l8wcpKQuw7qjJl+nDaNpUca6b4EiZUDer0ueRYMiVz8Ik7+b1N37iz3WDKSkLMOGA0z1xxclsLPB+jBld0P1GOOjv3Af71V4S6fo2J96CsJPW9yTRveUk4r2SevJ58lYZDfPao8VlP39X7ku36Mi1zfBffyULK9/0aWFbC+yeOLHA0u0e3Cd3M7gFOBKrMrBb4DlAK4JybAzwCnAasBBqB83sr2GS/f+HdtiSZjUQDdWdLlD2GFD4pSHZ6ksxFpGvZ9HI5p5vnHfD/ChZRDiKxzuurXZm659ACRyIi0vcCeaVootvXhcdNzHqe5IPhEYPKChyRiEjfC2RC39niz2APrsj+xFjyScHSHtYGRUT6o0BmtkRXwEE51NCTlXVy8lNEJMgCmdkS3czKc2hpJ5dc0nsjiIgUg0Am9MTFICXpffm6kNwNu7PuiSIiQRbIzBZJug9FPlRyEZFiFMjM1hrxLfRcEnpKC10nRUWkCAUysyXuFJdTySWpiq4WuogUo0Bmtki8hl4ayi/8fO9NISLSnwUyobdGEzX0HBJz0qQlSugiUoQCndDT74rYleQUHlJCF5EiFMiE3lZyyaWFnkQtdBEpRsFM6ImTojnU0JMv/Q9luDe4iEjQBTKhp//YQzaSp8yld4yISFAENKH7jJ5v5SSsFrqIFKFAJvTE7zJm+lm1ziRPqm6LIlKMApnQXV4ll85/Rk1EpBgEMqH3uOSihC4iRSigCd0/5tJbRSUXESl2wUzobTX07OdJnlQJXUSKUTATerzkkm9iVi8XESlGAU3o/jGnC4RUchGRIhfQhJ5PyaV94ly6O4qIBEWgE7ou4RcRaRfMhB6vueRSC1fuF5FiF8yEnk+3xV6KRUSkvwhoQo/X0AMZvYhI78gqJZrZTDNbYWYrzeyKDM8PN7MHzexVM/u3mR1Y+FDb5VND14lQESl23SZ0MwsDvwJOBaYA55jZlLTJrgQWO+cOBj4L3FjoQJO13T5XNXQRkTbZtNCPAFY651Y551qAecCstGmmAH8HcM4tB8ab2eiCRpokv26LIiLFLZuEPhZYkzRcGx+X7BXgowBmdgSwN1CTviAzu9DMFprZwrq6uvwipv1ui+q2KCLSLpuEnilrurTh64DhZrYY+G/gZSDSYSbn5jrnpjvnpldXV+ccbELifui5XPCp3C8ixa4ki2lqgXFJwzXAuuQJnHPbgfMBzJ99fDv+1yvyu5eLMrqIFLdsWugvApPMbIKZlQGzgfnJE5jZsPhzAF8EFsSTfK9InBRVzxURkXbdttCdcxEzuwR4HAgDtzrnlprZRfHn5wAHAHeYWRRYBnyhF2PGOZfzj1so94tIscum5IJz7hHgkbRxc5L+fw6YVNjQOheNuZxPiCqfi0ixC+S1ljEHId0CV0QkRSATen4lF+0ARKS4BTKhx5xKLiIi6QKZ0KMxXVQkIpIukAk9pl4uIiIdBDKhO+dyPilqKrqISJELZEKP5lFDFxEpdoFM6DGX231cQCUXESl+gUzoTi10EZEOApnQY+rlIiLSQSATelS9XEREOghkQo85l/OVn+rlIiLFLpAJ3blc74UuIlL8ApnQdWGRiEhHgUzoed0+VwldRIpcIBO6c0rQIiLpApnQY87lXEPXSVERKXaBTegquYiIpApkQo/G9IMVIiLpApnQnXOEc4xc6V9Eil0gE7pKLiIiHQU0oavkIiKSLqAJPfcLi1R0EZFiF9iEHlbJRUQkRTATum6fKyLSQTATunM5t7iV/kWk2AU2oefey0UpXUSKW0ATum6fKyKSLquEbmYzzWyFma00sysyPD/UzP5kZq+Y2VIzO7/wobZTyUVEpKNuE7qZhYFfAacCU4BzzGxK2mT/D1jmnJsGnAj81MzKChxrm5jL/aSoKi4iUuyyaaEfAax0zq1yzrUA84BZadM4YLD5QnUlsAWIFDTSJLFYPv3QRUSKWzYJfSywJmm4Nj4u2U3AAcA6YAnwFedcLH1BZnahmS00s4V1dXV5hqzb54qIZJJNQs+UCV3a8IeAxcCewCHATWY2pMNMzs11zk13zk2vrq7OOdiEfC79V8lFRIpdNgm9FhiXNFyDb4knOx94wHkrgbeB/QsTYkcur0v/RUSKWzYJ/UVgkplNiJ/onA3MT5vmXWAGgJmNBvYDVhUy0GT5/KaoiEixK+luAudcxMwuAR4HwsCtzrmlZnZR/Pk5wLXAbWa2BF+iudw5t6m3go45RyjXGrryv4gUuW4TOoBz7hHgkbRxc5L+XwecUtjQuoon926LatGLSLEL6JWiudfQS8JK6CJS3AKZ0KN53MulNBTIlyoikrVAZrl8bp9bWhLIlyoikrWsauj9TT7dFkvUz1GkX2ltbaW2tpampqa+DqVfqqiooKamhtLS0qznCWRCz+deLqVhtdBF+pPa2loGDx7M+PHjdXvrNM45Nm/eTG1tLRMmTMh6vkBmuahz5FoS1+12RfqXpqYmRo4cqWSegZkxcuTInI9eApnQXR4nRUWk/1Ey71w+700gE3o+JRcRkWIX0ISe+w9ciIgUu2CeFM3zXi53feH97DViYC9EJCLS9wLZQk+/d2+2jp1UxV4jldBFpN2ZZ57JYYcdxtSpU5k7dy4Ajz32GIceeijTpk1jxowZADQ0NHD++edz0EEHcfDBB3P//ff3ZdgZBbKFjtPNtkSKyXf/tJRl67YXdJlT9hzCd06f2u10t956KyNGjGDXrl0cfvjhzJo1iwsuuIAFCxYwYcIEtmzZAsC1117L0KFDWbJkCQBbt24taLyFEMiE7tAvEIlIYfziF7/gwQcfBGDNmjXMnTuX448/vq3/94gRIwB44oknmDdvXtt8w4cP3/3BdiOYCV0nRUWKSjYt6d7wj3/8gyeeeILnnnuOgQMHcuKJJzJt2jRWrFjRYVqfd/p34glkDd13W+zrKEQk6Orr6xk+fDgDBw5k+fLlPP/88zQ3N/P000/z9ttvA7SVXE455RRuuummtnn7Y8klkAnd0f/3lCLS/82cOZNIJMLBBx/Mt771LY488kiqq6uZO3cuH/3oR5k2bRqf/OQnAbj66qvZunUrBx54INOmTeOpp57q4+g7CmjJJfMvV4uI5KK8vJxHH30043OnnnpqynBlZSW333777ggrbwFtoaOMLiKSJpAJHadeLiIi6QKZ0H0Nva+jEBHpX4KZ0FVDFxHpIJgJHV0pKiKSLpgJXfdDFxHpIJAJPaaSi4hIB4FM6IBqLiKyW1VWVvZ1CN0KXEJ3zt88V+lcRCRV4K4UjedzNdBFismjV8D6JYVd5h4HwanXdfr05Zdfzt57783FF18MwDXXXIOZsWDBArZu3Uprayvf//73mTVrVreramhoYNasWRnnu+OOO7jhhhswMw4++GDuvPNONmzYwEUXXcSqVasAuPnmmzn66KN7/JKzSuhmNhO4EQgDtzjnrkt7/n+ATyct8wCg2jm3pccRpkn8uIUuLBKRnpg9ezaXXnppW0K/9957eeyxx7jssssYMmQImzZt4sgjj+SMM87o9t5RFRUVPPjggx3mW7ZsGT/4wQ945plnqKqqarvR15e//GVOOOEEHnzwQaLRKA0NDQV5Td0mdDMLA78CPgjUAi+a2Xzn3LLENM6564Hr49OfDlzWG8k8vq54XL2xdBHpE120pHvL+973PjZu3Mi6deuoq6tj+PDhjBkzhssuu4wFCxYQCoVYu3YtGzZsYI899uhyWc45rrzyyg7zPfnkk5x99tlUVVUB7fdWf/LJJ7njjjsACIfDDB06tCCvKZsW+hHASufcKgAzmwfMApZ1Mv05wD0FiS6D9ha6iEjPnH322dx3332sX7+e2bNnc/fdd1NXV8eiRYsoLS1l/PjxNDU1dbuczubb3fdQz+ak6FhgTdJwbXxcB2Y2EJgJZPyxPTO70MwWmtnCurq6XGMFVEMXkcKZPXs28+bN47777uPss8+mvr6eUaNGUVpaylNPPcXq1auzWk5n882YMYN7772XzZs3A+33Vp8xYwY333wzANFolO3bC/Pze9kk9Eyps7PfaT4deKazcotzbq5zbrpzbnp1dXW2MaatOFFyUUYXkZ6ZOnUqO3bsYOzYsYwZM4ZPf/rTLFy4kOnTp3P33Xez//77Z7WczuabOnUqV111FSeccALTpk3jq1/9KgA33ngjTz31FAcddBCHHXYYS5cuLcjryabkUguMSxquAdZ1Mu1serHcAmqhi0hhJX70GaCqqornnnsu43Rdnbjsar7zzjuP8847L2Xc6NGjefjhh/OItmvZtNBfBCaZ2QQzK8Mn7fnpE5nZUOAEoPBRJmlL6Kqii4ik6LaF7pyLmNklwOP4bou3OueWmtlF8efnxCc9C/irc25nr0VLcsmlN9ciItLRkiVL+MxnPpMyrry8nBdeeKGPIkqVVT9059wjwCNp4+akDd8G3FaowDqPxT8qn4sE3+7uBdJTBx10EIsXL94t60p00c5F8C79jz8G6DsgIhlUVFSwefPmvBJXsXPOsXnzZioqKnKaL4CX/ifu5aKMLhJkNTU11NbWkm8X5mJXUVFBTU1NTvMEL6HHH9VCFwm20tJSJkyY0NdhFJXglVx0dCYiklHgEnqiia5fLBIRSRW4hB7TzblERDIKXELXzblERDILXkJ3upeLiEgmwUvo8UflcxGRVMFL6LpSVEQko+AldHS7RRGRTAKX0FELXUQko8AldNXQRUQyC15C14VFIiIZBS6ht11Y1MdxiIj0N4FL6Cq5iIhkFryErtvniohkFMCEHv9H+VxEJEXgEnqC8rmISKrAJfS2K0VVRBcRSRG8hI56uYiIZBK8hJ7ohx64yEVEelfg0mJMvVxERDIKXEJXP3QRkcyCl9D1I9EiIhkFLqEn2ujq5SIikipwCV0/cCEiklnwEnr8UQ10EZFUWSV0M5tpZivMbKWZXdHJNCea2WIzW2pmTxc2zHbtLXRldBGRZCXdTWBmYeBXwAeBWuBFM5vvnFuWNM0w4NfATOfcu2Y2qrcCbruwSPlcRCRFNi30I4CVzrlVzrkWYB4wK22aTwEPOOfeBXDObSxsmO3af+Cit9YgIhJM2ST0scCapOHa+Lhkk4HhZvYPM1tkZp/NtCAzu9DMFprZwrq6urwCjul2iyIiGWWT0DNlzvTe4CXAYcCHgQ8B3zKzyR1mcm6uc266c256dXV1zsH6ZcSDUj4XEUnRbQ0d3yIflzRcA6zLMM0m59xOYKeZLQCmAW8UJMoMlM9FRFJl00J/EZhkZhPMrAyYDcxPm+Zh4DgzKzGzgcD7gdcLG6qn2+eKiGTWbQvdORcxs0uAx4EwcKtzbqmZXRR/fo5z7nUzewx4FYgBtzjnXuuNgHX7XBGRzLIpueCcewR4JG3cnLTh64HrCxdaZ7H4RzXQRURS6UpREZEiEbyErvuhi4hkFLyEHn9UC11EJFXwErrT7XNFRDIJYEL3j0rnIiKpgpfQ449qoIuIpApeQtftc0VEMgpgQtftc0VEMgleQo8/Kp+LiKQKXkJXRhcRySh4CR1dWCQikkngEjr6xSIRkYwCl9Bjun2uiEhGgUvo+pFoEZHMgpfQdaWoiEhGwUvo8Ue10EVEUgUvoavfoohIRsFL6PFHtdBFRFIFLqGTbw3dOdi+rtDRiIj0G4FL6IleLqFcm+gv3QE/OwDWvdwLUYmI9L3AJfRYzD/mXHJZ/Yx/3Li8oPGIiPQXgUvo7adEc8zoFvaPsUhB4xER6S+Cl9DzvX1uKP5SXaywAYmI9BPBS+j5zphoobtooUIREelXgpfQHezJJsp2vJvbjKFEyUUJXf5DxaLw4/Hw8t19HYn0ksAldHA8W/FlJs87Flp2Zj9bWwtdJRcJqMYt7b0C8tG6C3Zthb98rXAxSb8SuITukmsuP9wz+xnVQpcga9wCP5kAT30//2UkOgSo7Fi0skroZjbTzFaY2UozuyLD8yeaWb2ZLY7/fbvwoXp519Cl78VisPyRtL2yZCVxNPryXfkvI5HQ1dOraHWb0M0sDPwKOBWYApxjZlMyTPpP59wh8b/vFTjONi6mZBBYL90O886Bf8/t60h67k9fgaUP7b71JVrVDRvgto/Ajg2wY31uy4i2xpelsmOxyqaFfgSw0jm3yjnXAswDZvVuWJ0bWNrTL6N2CH2mcZN/fPQbfRtHT7U0wqLb4I/n7b6jjUQyBnjnn/DTyfDT/eDXR8POzdktI9ba/TQSaNkk9LHAmqTh2vi4dEeZ2Stm9qiZTc20IDO70MwWmtnCurq6PMKFkyYOSR2x+a0s54x3XF+/BNb8O691Sw+VDuzrCApj1VPt/393GPzpUlh8T+Zp3/wb1Ne2D792PzRtz32dkebM4zcuhXefzbDeJzpuG1El9Kxtfw9WPNbXUeQsm4Se6RKe9GbJS8DezrlpwC+BjMeizrm5zrnpzrnp1dXVuUWakP7F/uWh8MyN8OfL4Kkf+Xu1ZGo1JQ4zX7kHfvvB/NYtPTNgROpw7SK/4WxbA2vj/wdB7cLU4UW/g4cugr+nVRrXLYa7z4Y5x/rhja/DfZ+H+ZekThdphg1Lu15ntMU/jp3ePu6A0/1j/drU5L11Ndz9Mb9tXDMUbpzm17Hpzexen8BtH4Z7PtmzXkV9oCSLaWqBcUnDNUDKbQudc9uT/n/EzH5tZlXOuU2FCTNJpKnjuL8lnYN9+jrY/yNQczgce2n7+H//JnWeWLS958t/sqbtUD44t0tvW5sgVALhbL4+cY1b4M9Jn8eO9XDLyR2nO+RcaNkBZ87xJYJYFAaO6DhdX+qstfzPn8Ihn4YRE+Gdf8HtH/Hjd22F5gZfqgGfcJP96Su+ofHV12HQKH/SsrQidZpE6/qkK6FqMrz+Jzjwo/7xscv93/HfgIb1/kZ0yba+A9dPgub6Hr3s/wiR+I5zS3wH2doI5ZV9F0+OsmmhvwhMMrMJZlYGzAbmJ09gZntY/FebzeyI+HKzLOzlqDmLw9Xlf4YnvuP/b6qHf/1vx2m2r8193Qt/Bw1dlIqW3AebVua+3L7gHDx9PVw3Dv5xXW7z/mC0bwGCPyKa/2Xf2gbfonn+Znjjr/Do5b5VuHW173KXvDNe+ffMy158Fyx7GH44Bq7by893w37tG1pCtBWevQmad+QWeyFEW/zRxqWvwfjjUp/75aHw6yNhcdrFOz8a274DSz4p2drkkznAotvhD+f697fDOuM7kXAZDBsHR13sd8TJFvykYzJPUDLPzo9q4PtJ1YPWxr6LJQ/dNrGccxEzuwR4HAgDtzrnlprZRfHn5wBnA18yswiwC5jtXC+dLdoZT6j7zIC3OkkKCdcMhckz4Y0MtbDt62DYXqnjahdC+RBo3Ql7vi/1ufpa38JcfDd88Qk/rqXRL7u+Fqr3g/u/0D79Zx6EfU72NdSyQb6ksN9pfoM//1Gf5B66yE/7P2/BoKquX8uaF6F6MlQM7Xq6Dctgx3tQvT8MzXSqA79TWnB9+1HL09fBkj/Cxc/51zP+uNRW8YrH/OHnCZf71ibAqn/4x1s+4FuUL90OFzwFa16Ax5J6tr4wJ3MMD1/sH/f9ALz3CoyclLkWDL7V+fuPQ1klvPWUT2QN8R4ef73KP379Tagc5f/f9q7/bEbt3+nb1K0Ny/x6ho3r+Fy0pT2xHvIpf5IyWd1y/9eZ9a/6o8oPfg9+dXj7+KeTdqw7N8PSB2DMNP+ZJ0ou4bL2abo6JzFyX9gcb1x8/U2Yc1z7e9aVdS9D5R4wZEz30/YW5+Cm6TB8AhzzZT888QT/3JoX/bb0vnPh3edh1AH+O3nbafCB78L087NfT32t3wEefgE8eyM8+8uO09wwCa7eCCXlhXltvSyrY2bn3CPAI2nj5iT9fxNwU2FD60SihTxwZHbTZ0rm4FvuySLNcMuM9uGJJ8GBH/Mb5oiJsDNePdqwzJcP7v2sbyWueT7z8u88yyepzUl1y7cXtD+X3FpddBsc/3X/f3OD/6IufRBO/bH/sv7hXHhvMex1NMy6yZ8vmDYblv8Fzvx1apK/+aj2/y0Ekz4EM38Eg8f4Q+8d6/z60215y3fDe/BCP/ytTX6n89er4Y1H/binf5w6z+NXpfZp/r+TMr8XnakcDefenzrOOXjiGn/i8TMP+Q3uie+070DA73DT3TDJ74RPvNInf4Ar34OyDEnPOZ9Uq/f3G2qkBTa8Bo9fCfud6lDQCncAAA1iSURBVD/738Rb3iddDU3boH4NnDXXl0ISCR1g2jm+j/heR0LVfqmtu648c6OPd1snt7C4fmLq8Aev9Y/JpRgzuKbel6UW3ea/E2WD4PU/+0S3+S0Yvrff0X19BUQjcG18u/leFXzuLz6GkjLYtc03aBJHXt01Mprq/d/2dTDu/e0lu0gz3PUx/7qG7eV3iu//L///kBq/rnRb3vbJ9eW74EM/9I2CzSv938q/ZV7/Y5d3HPfnS+Ggj8PfvgUHnAH7pH0fW3b6bTZcBm8+Dn/8nB+f/r1Ot/41qDms62n6CeuthnR3pk+f7hYuXNj9hOkiLb4v7r/nwrO/yD+Aj/4fHPwJ/yUPl8Di38NDX8pu3rLBvs5bSBNPgk/c7ssMuZh5HRyZFPc13bTgs3XQx32rvTd94k6Yckb30215G+4802/0n77PJ+JnfwkLf5v5nEqyqzf6x798zZ+k3PMQf5SVT1/sz/8V9nq/P7H53ivw34s6TrP4nvYjr95wyUKompT//PeeB8uS+ixUTYZLXvQ7+beebB9/6Gf9aznxCp/0t6/1293mVX5n8bdvtU97+AW+n/xRl8CT1/rGSCb7neZ3EtEInHWzH1e7KPO5lEK4pt73QFpyHxz7FXjpTti2uvv50iWOtvsJM1vknJue8bnAJfSER76ReqJzyNjc6uJTP+oPaaFwCfozD8GLt/ga/u508fPw/K99GeqP5+3edYMvxXTXykk3eSZ86g89X3dzg6/VN27yJwV3bYVNK3xruzdVDIMrMiSHWMy3cg/5dGoJLl8nXJFairlsKQytyX95918AS+5NHTdoFOyM7/gOON2faM3XmGl+Zzdqqu9S2SnzrfHHv9nFsg7xR6b5OuYr/kioEGZ827f6e7IzLZDiTOjvPOPrZgndfoF6ybkP+LLO8f/TXsN971V/guroL/tyzT3nQG2Gvu+n3eA3/PvO77w0lMk+J/uyTCFO2FTt5xNgvs6aC9M+mfuRwecegfHH5L/e7jzwX/DqvPbhfU6GUCkM2dOXAV74TfuJxnxd082Jxmzfky8+mbmVetV6XzZb/md/VADwjbd71uvn4Uvg5Tv9+5HcIgffMBh1ANzywfbva+Ue7bX3UAmc8gP/vo3cF954HFoafN/6ZGOmwTnz/E8+5uvEb/qjgxWPwtqX/A6n5nBfQpxzjD9a6Klz5sE9s+HMm7M/Ou/uM98NijOhJ/xsim+ZX7oEls33J8mGj4eSAVD3up/mon/5ulx3d5k75itw8rf9F6ark1oJiWTWnR3r/VV96RJfjp2b4ecHdkzQn3/c12YjLfCPH7b31rlsGQyqhjtmZT6ROGqK77q5x4EwYLi/TLxhvT8k/u4w37ps2gY1R8AX/+aXv+Z5Xw894Ay4YXL2Rywf/hkc/oXsktfMHwMO3n9RHr9QkoefTfH18kuXdN/FMlF6e2Wer0nv3OjPmzx3k2+dHfc1Pw34OvSgUfA/WfTr3roabjy44/iTr4Ynv+8/q4ufax9/++n+XEtnpbTOzgtka/kj/vYL597vT0hvXQ2/PMwnz8R5nFjU/yXXuyMtgOt4ctA5P21ro+8xBTDtU76ksubf7dd8XF0H4VJfw37rSX+SfVC1LyENGObf21DYl9UW/97H0lm34roVvnSU2L4TvvQs3H5G+xXJ3UlOzunb6KGfzdxj6Ju1HXsX7WbFndBbdvoTc4kTg7u2+S8OwE8m+kP7T9zuh9/+p6+9vz6/43IsDN/Z0j688u9w10dTp/nqcl8r/N/4hbDZ7q2bG3y3NYCzfuNbNVtXwynXpk73yh98j4mX78y8fOd8D5Yhe7YPb1/rd17X7wM4OPBsOPu3nceSuEoxFvG9JNL7O4PfQDe96XvuRJrggQv8SbnSAb5l9Jvj26f9+G0w9Sy4+VjYsMSPG7YXNG5N3SlkmwALKXECvTLPi9ic8zu59N5CzTv8cxVDMs+Xbvs633vq7QU+mYI/6dzSAOHy1AS9aSX8/bvwsVtSk+fq53z3xtNv7PnOcPs6f5K80DtV52DjMt+gKhvkx9W94d+/xHBC/Vr/Pe5JDN8b6b/H5z7gdwJn/cafMG9p9OcJEr2tjr3MN172PKT9qCF9ewfYsgp+Ee/d9t8v+R5pCeVDfdfPS1/L3PNpNyruhJ6P389u77mRkGnP+6Nxvt/7pUt8C6VqXz9+4+t+A+2sW2AmK//u62/pXSUz2bbG37u6enL2y9+43PfMuOiZ3ObLl3O+J8rEk/xGedfHYOUTcMYvfR127SI/LuFTf4TJp/R+XP3drm2+90lAek30a/W1voEyOtO9AvEJ2jkYuU/7uPWv+SPwkgFwdYZunP/6OTzzc7j8HVj9rN/h3nKyP0r7+/fg7Fv9kcWEeKNm8T3+yP9L//I7qfLBfseR8NDFvpE26UN++3/0G7DXUfD5/G8roISebus7vpvX4Rd0nZS3rPL1u4PO3l2RBdfOzf7IJ7kf8A2T/dHJVes6n09kd9r0pu/jXjYYrqztfvqElU+kNlCG7e2PcjJ1Wz7jJph6ZvwXovbOvLwvPpn3Tr2rhJ7DtdtFZPh4+MA13U83YqL/k+4NGtnxoo7Llure59K/JK4fSPxofLaGT0gd3rba55FM5l/S8X496ZY+0CtHaf+ZCV12j8S5DJH+InFeIpRj6ktu2H3mIX9+acievsxiIX9l7aY3/T18ku9ZBB1PZC97uOOV6AWihC4i/zks3jIvz/KEdtt85m/ZMWC479qZkFyyrZrk/6af336h4qxfd+yVNKX3fk5CCV1E/nMMqvZdRg/8WPfTptv76OynPeRTcPDs3Es7PaSELiL/Ocz8RYC7w25O5pDlj0SLiEj/p4QuIlIklNBFRIqEErqISJFQQhcRKRJK6CIiRUIJXUSkSCihi4gUiT6726KZ1QF5/MAfAFVAlnex7zOKsef6e3zQ/2Ps7/GBYszV3s65jDf577OE3hNmtrCz20f2F4qx5/p7fND/Y+zv8YFiLCSVXEREioQSuohIkQhqQp/b1wFkQTH2XH+PD/p/jP09PlCMBRPIGrqIiHQU1Ba6iIikUUIXESkSgUvoZjbTzFaY2Uozu6KPYhhnZk+Z2etmttTMvhIfP8LM/mZmb8YfhyfN8814zCvM7EO7Mdawmb1sZn/ubzGa2TAzu8/Mlsffy6P6U3zxdV4W/4xfM7N7zKyir2M0s1vNbKOZvZY0LueYzOwwM1sSf+4XZma9GN/18c/5VTN70MyG9VV8ncWY9NzXzcyZWVVfxpgX51xg/oAw8BYwESgDXgGm9EEcY4BD4/8PBt4ApgA/Aa6Ij78C+HH8/ynxWMuBCfHXEN5NsX4V+D3w5/hwv4kRuB34Yvz/MmBYP4tvLPA2MCA+fC/wub6OETgeOBR4LWlczjEB/waOAgx4FDi1F+M7BSiJ///jvoyvsxjj48cBj+Mveqzqyxjz+QtaC/0IYKVzbpVzrgWYB/TeL652wjn3nnPupfj/O4DX8Rv/LHySIv54Zvz/WcA851yzc+5tYCX+tfQqM6sBPgzckjS6X8RoZkPwG9VvAZxzLc65bf0lviQlwAAzKwEGAuv6Okbn3AJgS9ronGIyszHAEOfcc85npjuS5il4fM65vzrnIvHB54Gavoqvsxjj/hf4BpDcW6RPYsxH0BL6WGBN0nBtfFyfMbPxwPuAF4DRzrn3wCd9YFR8sr6K++f4L2csaVx/iXEiUAf8Ll4SusXMBvWj+HDOrQVuAN4F3gPqnXN/7U8xJsk1prHx/9PH7w6fx7dmoR/FZ2ZnAGudc6+kPdVvYuxO0BJ6pvpUn/W7NLNK4H7gUufc9q4mzTCuV+M2s48AG51zi7KdJcO43oyxBH/Ie7Nz7n3ATnypoDN98R4Ox7fOJgB7AoPM7NyuZskwrq/7BXcWU5/EamZXARHg7sSoTuLYrfGZ2UDgKuDbmZ7uJJZ+93kHLaHX4mtcCTX4Q+DdzsxK8cn8bufcA/HRG+KHYcQfN8bH90XcxwBnmNk7+NLUyWZ2Vz+KsRaodc69EB++D5/g+0t8AB8A3nbO1TnnWoEHgKP7WYwJucZUS3vZI3l8rzGz84CPAJ+Olyj6U3z74Hfcr8S3mRrgJTPbox/F2K2gJfQXgUlmNsHMyoDZwPzdHUT8TPZvgdedcz9Lemo+cF78//OAh5PGzzazcjObAEzCn0zpNc65bzrnapxz4/Hv05POuXP7S4zOufXAGjPbLz5qBrCsv8QX9y5wpJkNjH/mM/DnS/pTjAk5xRQvy+wwsyPjr+2zSfMUnJnNBC4HznDONabF3efxOeeWOOdGOefGx7eZWnzHh/X9Jcas9OUZ2Xz+gNPwvUreAq7qoxiOxR9avQosjv+dBowE/g68GX8ckTTPVfGYV7Cbz4QDJ9Ley6XfxAgcAiyMv48PAcP7U3zxdX4XWA68BtyJ7+nQpzEC9+Br+q34xPOFfGICpsdf11vATcSvHO+l+Fbi69CJ7WVOX8XXWYxpz79DvJdLX8WYz58u/RcRKRJBK7mIiEgnlNBFRIqEErqISJFQQhcRKRJK6CIiRUIJXUSkSCihi4gUif8PzIywzzOtbbMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history[\"val_accuracy\"])\n",
    "plt.legend([\"acc\",\"val_acc\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_first = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history[\"val_accuracy\"])\n",
    "plt.legend([\"acc\",\"val_acc\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5775400996208191"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history[\"val_accuracy\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_143 (Dense)            (None, 200)               153800    \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 195,001\n",
      "Trainable params: 194,601\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the Dense Model\n",
    "\n",
    "n_features = 768\n",
    "model = Sequential()\n",
    "model.add(Input(n_features))\n",
    "model.add(Dense(200, activation='elu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(200, activation='elu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss= \"binary_crossentropy\", optimizer='adam', metrics = [\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2584 samples, validate on 623 samples\n",
      "Epoch 1/100\n",
      "2584/2584 [==============================] - ETA: 29s - loss: 0.9354 - acc: 0.53 - ETA: 1s - loss: 0.9286 - acc: 0.4779 - ETA: 0s - loss: 0.9303 - acc: 0.483 - ETA: 0s - loss: 0.9102 - acc: 0.487 - ETA: 0s - loss: 0.8932 - acc: 0.484 - 1s 275us/sample - loss: 0.8870 - acc: 0.4876 - val_loss: 0.7002 - val_acc: 0.4783\n",
      "Epoch 2/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6541 - acc: 0.718 - ETA: 0s - loss: 0.8229 - acc: 0.526 - ETA: 0s - loss: 0.8129 - acc: 0.524 - ETA: 0s - loss: 0.8126 - acc: 0.509 - ETA: 0s - loss: 0.8133 - acc: 0.501 - 0s 109us/sample - loss: 0.8116 - acc: 0.5012 - val_loss: 0.7048 - val_acc: 0.5024\n",
      "Epoch 3/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.9885 - acc: 0.406 - ETA: 0s - loss: 0.8339 - acc: 0.468 - ETA: 0s - loss: 0.7976 - acc: 0.508 - ETA: 0s - loss: 0.7933 - acc: 0.504 - ETA: 0s - loss: 0.7895 - acc: 0.505 - 0s 110us/sample - loss: 0.7852 - acc: 0.5112 - val_loss: 0.7019 - val_acc: 0.5088\n",
      "Epoch 4/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.8626 - acc: 0.500 - ETA: 0s - loss: 0.7670 - acc: 0.523 - ETA: 0s - loss: 0.7602 - acc: 0.522 - ETA: 0s - loss: 0.7634 - acc: 0.513 - ETA: 0s - loss: 0.7613 - acc: 0.519 - 0s 113us/sample - loss: 0.7577 - acc: 0.5205 - val_loss: 0.6978 - val_acc: 0.5024\n",
      "Epoch 5/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7668 - acc: 0.406 - ETA: 0s - loss: 0.7793 - acc: 0.503 - ETA: 0s - loss: 0.7842 - acc: 0.484 - ETA: 0s - loss: 0.7715 - acc: 0.488 - ETA: 0s - loss: 0.7655 - acc: 0.486 - 0s 116us/sample - loss: 0.7635 - acc: 0.4861 - val_loss: 0.7014 - val_acc: 0.5281\n",
      "Epoch 6/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6661 - acc: 0.562 - ETA: 0s - loss: 0.7320 - acc: 0.524 - ETA: 0s - loss: 0.7427 - acc: 0.521 - ETA: 0s - loss: 0.7445 - acc: 0.507 - ETA: 0s - loss: 0.7402 - acc: 0.510 - 0s 110us/sample - loss: 0.7415 - acc: 0.5089 - val_loss: 0.6963 - val_acc: 0.5120\n",
      "Epoch 7/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6347 - acc: 0.500 - ETA: 0s - loss: 0.7249 - acc: 0.500 - ETA: 0s - loss: 0.7307 - acc: 0.518 - ETA: 0s - loss: 0.7274 - acc: 0.527 - ETA: 0s - loss: 0.7225 - acc: 0.532 - 0s 111us/sample - loss: 0.7250 - acc: 0.5286 - val_loss: 0.6910 - val_acc: 0.5425\n",
      "Epoch 8/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7625 - acc: 0.406 - ETA: 0s - loss: 0.7209 - acc: 0.500 - ETA: 0s - loss: 0.7238 - acc: 0.510 - ETA: 0s - loss: 0.7226 - acc: 0.510 - ETA: 0s - loss: 0.7232 - acc: 0.504 - 0s 112us/sample - loss: 0.7250 - acc: 0.4981 - val_loss: 0.6935 - val_acc: 0.5457\n",
      "Epoch 9/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6737 - acc: 0.593 - ETA: 0s - loss: 0.7160 - acc: 0.517 - ETA: 0s - loss: 0.7157 - acc: 0.513 - ETA: 0s - loss: 0.7146 - acc: 0.516 - ETA: 0s - loss: 0.7186 - acc: 0.506 - 0s 116us/sample - loss: 0.7192 - acc: 0.5039 - val_loss: 0.6918 - val_acc: 0.5329\n",
      "Epoch 10/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6535 - acc: 0.593 - ETA: 0s - loss: 0.7173 - acc: 0.480 - ETA: 0s - loss: 0.7134 - acc: 0.492 - ETA: 0s - loss: 0.7075 - acc: 0.506 - ETA: 0s - loss: 0.7100 - acc: 0.498 - 0s 111us/sample - loss: 0.7108 - acc: 0.5004 - val_loss: 0.6957 - val_acc: 0.5233\n",
      "Epoch 11/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7132 - acc: 0.437 - ETA: 0s - loss: 0.6999 - acc: 0.506 - ETA: 0s - loss: 0.6978 - acc: 0.518 - ETA: 0s - loss: 0.7036 - acc: 0.515 - ETA: 0s - loss: 0.7010 - acc: 0.523 - 0s 110us/sample - loss: 0.7023 - acc: 0.5240 - val_loss: 0.6973 - val_acc: 0.4735\n",
      "Epoch 12/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7315 - acc: 0.468 - ETA: 0s - loss: 0.7104 - acc: 0.518 - ETA: 0s - loss: 0.7105 - acc: 0.516 - ETA: 0s - loss: 0.7094 - acc: 0.511 - ETA: 0s - loss: 0.7078 - acc: 0.514 - 0s 117us/sample - loss: 0.7054 - acc: 0.5193 - val_loss: 0.6917 - val_acc: 0.5249\n",
      "Epoch 13/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7207 - acc: 0.468 - ETA: 0s - loss: 0.6981 - acc: 0.529 - ETA: 0s - loss: 0.7031 - acc: 0.523 - ETA: 0s - loss: 0.7000 - acc: 0.524 - ETA: 0s - loss: 0.7013 - acc: 0.515 - 0s 109us/sample - loss: 0.7019 - acc: 0.5174 - val_loss: 0.6921 - val_acc: 0.4880\n",
      "Epoch 14/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7061 - acc: 0.593 - ETA: 0s - loss: 0.7166 - acc: 0.473 - ETA: 0s - loss: 0.7086 - acc: 0.487 - ETA: 0s - loss: 0.7045 - acc: 0.497 - ETA: 0s - loss: 0.7049 - acc: 0.496 - 0s 108us/sample - loss: 0.7046 - acc: 0.4977 - val_loss: 0.6932 - val_acc: 0.4799\n",
      "Epoch 15/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6995 - acc: 0.593 - ETA: 0s - loss: 0.7066 - acc: 0.516 - ETA: 0s - loss: 0.7056 - acc: 0.506 - ETA: 0s - loss: 0.7052 - acc: 0.510 - ETA: 0s - loss: 0.7028 - acc: 0.508 - 0s 113us/sample - loss: 0.7012 - acc: 0.5159 - val_loss: 0.6958 - val_acc: 0.5056\n",
      "Epoch 16/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6567 - acc: 0.593 - ETA: 0s - loss: 0.6913 - acc: 0.546 - ETA: 0s - loss: 0.6941 - acc: 0.531 - ETA: 0s - loss: 0.6954 - acc: 0.518 - ETA: 0s - loss: 0.6969 - acc: 0.511 - 0s 115us/sample - loss: 0.6971 - acc: 0.5104 - val_loss: 0.6926 - val_acc: 0.5281\n",
      "Epoch 17/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6955 - acc: 0.500 - ETA: 0s - loss: 0.6965 - acc: 0.521 - ETA: 0s - loss: 0.6960 - acc: 0.532 - ETA: 0s - loss: 0.6983 - acc: 0.518 - ETA: 0s - loss: 0.6979 - acc: 0.510 - 0s 109us/sample - loss: 0.6992 - acc: 0.5066 - val_loss: 0.6905 - val_acc: 0.5233\n",
      "Epoch 18/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7014 - acc: 0.468 - ETA: 0s - loss: 0.6960 - acc: 0.495 - ETA: 0s - loss: 0.6997 - acc: 0.490 - ETA: 0s - loss: 0.6966 - acc: 0.502 - ETA: 0s - loss: 0.6968 - acc: 0.511 - 0s 109us/sample - loss: 0.6963 - acc: 0.5120 - val_loss: 0.6931 - val_acc: 0.5393\n",
      "Epoch 19/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6926 - acc: 0.562 - ETA: 0s - loss: 0.6966 - acc: 0.517 - ETA: 0s - loss: 0.6993 - acc: 0.520 - ETA: 0s - loss: 0.6976 - acc: 0.519 - ETA: 0s - loss: 0.6980 - acc: 0.512 - 0s 115us/sample - loss: 0.6977 - acc: 0.5112 - val_loss: 0.6931 - val_acc: 0.5313\n",
      "Epoch 20/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6837 - acc: 0.625 - ETA: 0s - loss: 0.6835 - acc: 0.585 - ETA: 0s - loss: 0.6921 - acc: 0.551 - ETA: 0s - loss: 0.6926 - acc: 0.544 - ETA: 0s - loss: 0.6931 - acc: 0.542 - 0s 108us/sample - loss: 0.6945 - acc: 0.5364 - val_loss: 0.6949 - val_acc: 0.5072\n",
      "Epoch 21/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7100 - acc: 0.437 - ETA: 0s - loss: 0.6899 - acc: 0.546 - ETA: 0s - loss: 0.6958 - acc: 0.526 - ETA: 0s - loss: 0.7005 - acc: 0.514 - ETA: 0s - loss: 0.7005 - acc: 0.506 - 0s 119us/sample - loss: 0.6993 - acc: 0.5046 - val_loss: 0.6960 - val_acc: 0.5056\n",
      "Epoch 22/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6985 - acc: 0.562 - ETA: 0s - loss: 0.6977 - acc: 0.498 - ETA: 0s - loss: 0.6985 - acc: 0.507 - ETA: 0s - loss: 0.6979 - acc: 0.510 - ETA: 0s - loss: 0.6986 - acc: 0.506 - 0s 114us/sample - loss: 0.6987 - acc: 0.5050 - val_loss: 0.6924 - val_acc: 0.5393\n",
      "Epoch 23/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7277 - acc: 0.406 - ETA: 0s - loss: 0.6981 - acc: 0.495 - ETA: 0s - loss: 0.6958 - acc: 0.497 - ETA: 0s - loss: 0.6948 - acc: 0.512 - ETA: 0s - loss: 0.6945 - acc: 0.506 - 0s 112us/sample - loss: 0.6954 - acc: 0.5027 - val_loss: 0.6949 - val_acc: 0.5072\n",
      "Epoch 24/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6831 - acc: 0.500 - ETA: 0s - loss: 0.6912 - acc: 0.519 - ETA: 0s - loss: 0.6985 - acc: 0.498 - ETA: 0s - loss: 0.6973 - acc: 0.498 - ETA: 0s - loss: 0.6964 - acc: 0.502 - 0s 112us/sample - loss: 0.6952 - acc: 0.5039 - val_loss: 0.6915 - val_acc: 0.5265\n",
      "Epoch 25/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.531 - ETA: 0s - loss: 0.7025 - acc: 0.482 - ETA: 0s - loss: 0.6936 - acc: 0.520 - ETA: 0s - loss: 0.6932 - acc: 0.520 - ETA: 0s - loss: 0.6934 - acc: 0.523 - 0s 112us/sample - loss: 0.6936 - acc: 0.5228 - val_loss: 0.6928 - val_acc: 0.5345\n",
      "Epoch 26/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7299 - acc: 0.375 - ETA: 0s - loss: 0.6950 - acc: 0.501 - ETA: 0s - loss: 0.6986 - acc: 0.498 - ETA: 0s - loss: 0.7004 - acc: 0.501 - ETA: 0s - loss: 0.7001 - acc: 0.502 - 0s 114us/sample - loss: 0.6992 - acc: 0.5066 - val_loss: 0.6941 - val_acc: 0.4719\n",
      "Epoch 27/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6796 - acc: 0.593 - ETA: 0s - loss: 0.6930 - acc: 0.546 - ETA: 0s - loss: 0.6928 - acc: 0.536 - ETA: 0s - loss: 0.6937 - acc: 0.527 - ETA: 0s - loss: 0.6947 - acc: 0.513 - 0s 110us/sample - loss: 0.6937 - acc: 0.5166 - val_loss: 0.6969 - val_acc: 0.5169\n",
      "Epoch 28/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7297 - acc: 0.375 - ETA: 0s - loss: 0.7015 - acc: 0.491 - ETA: 0s - loss: 0.6960 - acc: 0.510 - ETA: 0s - loss: 0.6952 - acc: 0.519 - ETA: 0s - loss: 0.6963 - acc: 0.511 - 0s 114us/sample - loss: 0.6964 - acc: 0.5120 - val_loss: 0.6976 - val_acc: 0.5072\n",
      "Epoch 29/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6776 - acc: 0.531 - ETA: 0s - loss: 0.6971 - acc: 0.518 - ETA: 0s - loss: 0.6951 - acc: 0.523 - ETA: 0s - loss: 0.6942 - acc: 0.523 - ETA: 0s - loss: 0.6953 - acc: 0.519 - 0s 111us/sample - loss: 0.6959 - acc: 0.5139 - val_loss: 0.6983 - val_acc: 0.4896\n",
      "Epoch 30/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6860 - acc: 0.500 - ETA: 0s - loss: 0.7007 - acc: 0.483 - ETA: 0s - loss: 0.6981 - acc: 0.496 - ETA: 0s - loss: 0.6973 - acc: 0.495 - ETA: 0s - loss: 0.6984 - acc: 0.489 - 0s 113us/sample - loss: 0.6978 - acc: 0.4930 - val_loss: 0.6960 - val_acc: 0.5185\n",
      "Epoch 31/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6819 - acc: 0.656 - ETA: 0s - loss: 0.6930 - acc: 0.537 - ETA: 0s - loss: 0.6954 - acc: 0.514 - ETA: 0s - loss: 0.6963 - acc: 0.512 - ETA: 0s - loss: 0.6963 - acc: 0.509 - 0s 109us/sample - loss: 0.6950 - acc: 0.5101 - val_loss: 0.6929 - val_acc: 0.5217\n",
      "Epoch 32/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6472 - acc: 0.656 - ETA: 0s - loss: 0.6945 - acc: 0.531 - ETA: 0s - loss: 0.6964 - acc: 0.513 - ETA: 0s - loss: 0.6966 - acc: 0.513 - ETA: 0s - loss: 0.6962 - acc: 0.509 - 0s 116us/sample - loss: 0.6943 - acc: 0.5182 - val_loss: 0.6941 - val_acc: 0.5281\n",
      "Epoch 33/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6982 - acc: 0.531 - ETA: 0s - loss: 0.6978 - acc: 0.520 - ETA: 0s - loss: 0.6925 - acc: 0.520 - ETA: 0s - loss: 0.6912 - acc: 0.527 - ETA: 0s - loss: 0.6934 - acc: 0.526 - 0s 112us/sample - loss: 0.6931 - acc: 0.5248 - val_loss: 0.6911 - val_acc: 0.5361\n",
      "Epoch 34/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7324 - acc: 0.437 - ETA: 0s - loss: 0.6981 - acc: 0.506 - ETA: 0s - loss: 0.6953 - acc: 0.528 - ETA: 0s - loss: 0.6982 - acc: 0.512 - ETA: 0s - loss: 0.6983 - acc: 0.510 - 0s 114us/sample - loss: 0.6975 - acc: 0.5116 - val_loss: 0.6929 - val_acc: 0.4831\n",
      "Epoch 35/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6966 - acc: 0.437 - ETA: 0s - loss: 0.6915 - acc: 0.521 - ETA: 0s - loss: 0.6875 - acc: 0.532 - ETA: 0s - loss: 0.6877 - acc: 0.530 - ETA: 0s - loss: 0.6881 - acc: 0.535 - 0s 111us/sample - loss: 0.6898 - acc: 0.5348 - val_loss: 0.7028 - val_acc: 0.5024\n",
      "Epoch 36/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6789 - acc: 0.562 - ETA: 0s - loss: 0.6924 - acc: 0.528 - ETA: 0s - loss: 0.6981 - acc: 0.511 - ETA: 0s - loss: 0.6966 - acc: 0.515 - ETA: 0s - loss: 0.6968 - acc: 0.515 - 0s 117us/sample - loss: 0.6970 - acc: 0.5155 - val_loss: 0.6968 - val_acc: 0.5217\n",
      "Epoch 37/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7209 - acc: 0.406 - ETA: 0s - loss: 0.7016 - acc: 0.477 - ETA: 0s - loss: 0.7019 - acc: 0.500 - ETA: 0s - loss: 0.6963 - acc: 0.521 - ETA: 0s - loss: 0.6955 - acc: 0.521 - 0s 118us/sample - loss: 0.6947 - acc: 0.5252 - val_loss: 0.7008 - val_acc: 0.4992\n",
      "Epoch 38/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6899 - acc: 0.562 - ETA: 0s - loss: 0.6890 - acc: 0.554 - ETA: 0s - loss: 0.6910 - acc: 0.539 - ETA: 0s - loss: 0.6910 - acc: 0.541 - ETA: 0s - loss: 0.6928 - acc: 0.533 - 0s 110us/sample - loss: 0.6946 - acc: 0.5306 - val_loss: 0.7011 - val_acc: 0.4848\n",
      "Epoch 39/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6800 - acc: 0.656 - ETA: 0s - loss: 0.6914 - acc: 0.548 - ETA: 0s - loss: 0.6940 - acc: 0.530 - ETA: 0s - loss: 0.6937 - acc: 0.526 - ETA: 0s - loss: 0.6929 - acc: 0.532 - 0s 108us/sample - loss: 0.6934 - acc: 0.5321 - val_loss: 0.6935 - val_acc: 0.5201\n",
      "Epoch 40/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7293 - acc: 0.250 - ETA: 0s - loss: 0.6967 - acc: 0.517 - ETA: 0s - loss: 0.6999 - acc: 0.501 - ETA: 0s - loss: 0.6989 - acc: 0.508 - ETA: 0s - loss: 0.6983 - acc: 0.513 - ETA: 0s - loss: 0.6970 - acc: 0.514 - 0s 128us/sample - loss: 0.6972 - acc: 0.5132 - val_loss: 0.6928 - val_acc: 0.5008\n",
      "Epoch 41/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.562 - ETA: 0s - loss: 0.6918 - acc: 0.516 - ETA: 0s - loss: 0.6929 - acc: 0.523 - ETA: 0s - loss: 0.6949 - acc: 0.509 - ETA: 0s - loss: 0.6938 - acc: 0.514 - 0s 114us/sample - loss: 0.6955 - acc: 0.5058 - val_loss: 0.6961 - val_acc: 0.4944\n",
      "Epoch 42/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7242 - acc: 0.531 - ETA: 0s - loss: 0.6880 - acc: 0.548 - ETA: 0s - loss: 0.6956 - acc: 0.525 - ETA: 0s - loss: 0.6953 - acc: 0.520 - ETA: 0s - loss: 0.6931 - acc: 0.517 - 0s 111us/sample - loss: 0.6934 - acc: 0.5159 - val_loss: 0.6927 - val_acc: 0.5474\n",
      "Epoch 43/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6920 - acc: 0.375 - ETA: 0s - loss: 0.6900 - acc: 0.521 - ETA: 0s - loss: 0.6927 - acc: 0.522 - ETA: 0s - loss: 0.6935 - acc: 0.518 - ETA: 0s - loss: 0.6941 - acc: 0.517 - 0s 108us/sample - loss: 0.6943 - acc: 0.5166 - val_loss: 0.6920 - val_acc: 0.5201\n",
      "Epoch 44/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7103 - acc: 0.500 - ETA: 0s - loss: 0.6962 - acc: 0.533 - ETA: 0s - loss: 0.6965 - acc: 0.525 - ETA: 0s - loss: 0.6990 - acc: 0.521 - ETA: 0s - loss: 0.6968 - acc: 0.526 - 0s 111us/sample - loss: 0.6963 - acc: 0.5252 - val_loss: 0.6910 - val_acc: 0.5281\n",
      "Epoch 45/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6919 - acc: 0.562 - ETA: 0s - loss: 0.7015 - acc: 0.489 - ETA: 0s - loss: 0.6984 - acc: 0.496 - ETA: 0s - loss: 0.6980 - acc: 0.497 - ETA: 0s - loss: 0.6964 - acc: 0.500 - 0s 109us/sample - loss: 0.6965 - acc: 0.5062 - val_loss: 0.6947 - val_acc: 0.5297\n",
      "Epoch 46/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6841 - acc: 0.531 - ETA: 0s - loss: 0.6943 - acc: 0.519 - ETA: 0s - loss: 0.6911 - acc: 0.533 - ETA: 0s - loss: 0.6943 - acc: 0.522 - ETA: 0s - loss: 0.6945 - acc: 0.523 - 0s 113us/sample - loss: 0.6941 - acc: 0.5236 - val_loss: 0.6934 - val_acc: 0.5169\n",
      "Epoch 47/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.531 - ETA: 0s - loss: 0.6905 - acc: 0.519 - ETA: 0s - loss: 0.6922 - acc: 0.526 - ETA: 0s - loss: 0.6948 - acc: 0.521 - ETA: 0s - loss: 0.6952 - acc: 0.515 - 0s 112us/sample - loss: 0.6950 - acc: 0.5143 - val_loss: 0.6927 - val_acc: 0.5088\n",
      "Epoch 48/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6813 - acc: 0.562 - ETA: 0s - loss: 0.6891 - acc: 0.543 - ETA: 0s - loss: 0.6923 - acc: 0.530 - ETA: 0s - loss: 0.6921 - acc: 0.524 - ETA: 0s - loss: 0.6912 - acc: 0.529 - 0s 111us/sample - loss: 0.6928 - acc: 0.5240 - val_loss: 0.6928 - val_acc: 0.5024\n",
      "Epoch 49/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6855 - acc: 0.500 - ETA: 0s - loss: 0.6970 - acc: 0.524 - ETA: 0s - loss: 0.6948 - acc: 0.524 - ETA: 0s - loss: 0.6964 - acc: 0.527 - ETA: 0s - loss: 0.6955 - acc: 0.524 - 0s 113us/sample - loss: 0.6952 - acc: 0.5232 - val_loss: 0.6935 - val_acc: 0.5217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6829 - acc: 0.531 - ETA: 0s - loss: 0.7016 - acc: 0.483 - ETA: 0s - loss: 0.6951 - acc: 0.518 - ETA: 0s - loss: 0.6939 - acc: 0.522 - ETA: 0s - loss: 0.6934 - acc: 0.526 - 0s 112us/sample - loss: 0.6932 - acc: 0.5236 - val_loss: 0.7047 - val_acc: 0.5056\n",
      "Epoch 51/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7282 - acc: 0.375 - ETA: 0s - loss: 0.6982 - acc: 0.490 - ETA: 0s - loss: 0.6949 - acc: 0.503 - ETA: 0s - loss: 0.6962 - acc: 0.496 - ETA: 0s - loss: 0.6961 - acc: 0.503 - 0s 114us/sample - loss: 0.6952 - acc: 0.5043 - val_loss: 0.6954 - val_acc: 0.5169\n",
      "Epoch 52/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7025 - acc: 0.531 - ETA: 0s - loss: 0.6898 - acc: 0.529 - ETA: 0s - loss: 0.6947 - acc: 0.522 - ETA: 0s - loss: 0.6955 - acc: 0.514 - ETA: 0s - loss: 0.6944 - acc: 0.514 - 0s 111us/sample - loss: 0.6944 - acc: 0.5147 - val_loss: 0.6990 - val_acc: 0.4912\n",
      "Epoch 53/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7179 - acc: 0.437 - ETA: 0s - loss: 0.6933 - acc: 0.523 - ETA: 0s - loss: 0.6938 - acc: 0.519 - ETA: 0s - loss: 0.6941 - acc: 0.518 - ETA: 0s - loss: 0.6942 - acc: 0.518 - 0s 110us/sample - loss: 0.6957 - acc: 0.5147 - val_loss: 0.6926 - val_acc: 0.5185\n",
      "Epoch 54/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7069 - acc: 0.500 - ETA: 0s - loss: 0.6977 - acc: 0.486 - ETA: 0s - loss: 0.6946 - acc: 0.499 - ETA: 0s - loss: 0.6933 - acc: 0.521 - ETA: 0s - loss: 0.6937 - acc: 0.519 - 0s 117us/sample - loss: 0.6935 - acc: 0.5232 - val_loss: 0.6944 - val_acc: 0.5072\n",
      "Epoch 55/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7041 - acc: 0.500 - ETA: 0s - loss: 0.6934 - acc: 0.516 - ETA: 0s - loss: 0.6901 - acc: 0.526 - ETA: 0s - loss: 0.6937 - acc: 0.528 - ETA: 0s - loss: 0.6936 - acc: 0.517 - 0s 115us/sample - loss: 0.6929 - acc: 0.5178 - val_loss: 0.6964 - val_acc: 0.5040\n",
      "Epoch 56/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6834 - acc: 0.562 - ETA: 0s - loss: 0.6985 - acc: 0.477 - ETA: 0s - loss: 0.6975 - acc: 0.496 - ETA: 0s - loss: 0.6974 - acc: 0.498 - ETA: 0s - loss: 0.6961 - acc: 0.510 - 0s 112us/sample - loss: 0.6955 - acc: 0.5108 - val_loss: 0.6917 - val_acc: 0.5329\n",
      "Epoch 57/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7091 - acc: 0.468 - ETA: 0s - loss: 0.6930 - acc: 0.523 - ETA: 0s - loss: 0.6927 - acc: 0.528 - ETA: 0s - loss: 0.6956 - acc: 0.520 - ETA: 0s - loss: 0.6973 - acc: 0.509 - ETA: 0s - loss: 0.6964 - acc: 0.515 - 0s 125us/sample - loss: 0.6966 - acc: 0.5120 - val_loss: 0.6972 - val_acc: 0.5152\n",
      "Epoch 58/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7183 - acc: 0.468 - ETA: 0s - loss: 0.6820 - acc: 0.564 - ETA: 0s - loss: 0.6888 - acc: 0.557 - ETA: 0s - loss: 0.6884 - acc: 0.548 - ETA: 0s - loss: 0.6886 - acc: 0.545 - 0s 117us/sample - loss: 0.6888 - acc: 0.5414 - val_loss: 0.6966 - val_acc: 0.4976\n",
      "Epoch 59/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6875 - acc: 0.625 - ETA: 0s - loss: 0.6863 - acc: 0.536 - ETA: 0s - loss: 0.6933 - acc: 0.528 - ETA: 0s - loss: 0.6916 - acc: 0.525 - ETA: 0s - loss: 0.6939 - acc: 0.522 - 0s 115us/sample - loss: 0.6925 - acc: 0.5271 - val_loss: 0.6921 - val_acc: 0.5217\n",
      "Epoch 60/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.468 - ETA: 0s - loss: 0.6887 - acc: 0.525 - ETA: 0s - loss: 0.6877 - acc: 0.541 - ETA: 0s - loss: 0.6900 - acc: 0.535 - ETA: 0s - loss: 0.6926 - acc: 0.527 - ETA: 0s - loss: 0.6934 - acc: 0.527 - 0s 125us/sample - loss: 0.6932 - acc: 0.5283 - val_loss: 0.6954 - val_acc: 0.5024\n",
      "Epoch 61/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6363 - acc: 0.656 - ETA: 0s - loss: 0.6938 - acc: 0.496 - ETA: 0s - loss: 0.6896 - acc: 0.518 - ETA: 0s - loss: 0.6888 - acc: 0.524 - ETA: 0s - loss: 0.6881 - acc: 0.539 - 0s 122us/sample - loss: 0.6909 - acc: 0.5317 - val_loss: 0.7058 - val_acc: 0.4992\n",
      "Epoch 62/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6817 - acc: 0.531 - ETA: 0s - loss: 0.6980 - acc: 0.509 - ETA: 0s - loss: 0.6964 - acc: 0.522 - ETA: 0s - loss: 0.6940 - acc: 0.524 - ETA: 0s - loss: 0.6954 - acc: 0.520 - 0s 114us/sample - loss: 0.6945 - acc: 0.5228 - val_loss: 0.6960 - val_acc: 0.5249\n",
      "Epoch 63/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6901 - acc: 0.562 - ETA: 0s - loss: 0.6944 - acc: 0.519 - ETA: 0s - loss: 0.6940 - acc: 0.517 - ETA: 0s - loss: 0.6917 - acc: 0.525 - ETA: 0s - loss: 0.6916 - acc: 0.527 - 0s 110us/sample - loss: 0.6923 - acc: 0.5248 - val_loss: 0.6939 - val_acc: 0.5136\n",
      "Epoch 64/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6881 - acc: 0.562 - ETA: 0s - loss: 0.6899 - acc: 0.527 - ETA: 0s - loss: 0.6842 - acc: 0.558 - ETA: 0s - loss: 0.6898 - acc: 0.546 - ETA: 0s - loss: 0.6907 - acc: 0.547 - 0s 110us/sample - loss: 0.6903 - acc: 0.5488 - val_loss: 0.6945 - val_acc: 0.5008\n",
      "Epoch 65/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6826 - acc: 0.500 - ETA: 0s - loss: 0.6805 - acc: 0.548 - ETA: 0s - loss: 0.6940 - acc: 0.517 - ETA: 0s - loss: 0.6910 - acc: 0.523 - ETA: 0s - loss: 0.6921 - acc: 0.523 - 0s 113us/sample - loss: 0.6919 - acc: 0.5232 - val_loss: 0.6997 - val_acc: 0.5169\n",
      "Epoch 66/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6990 - acc: 0.562 - ETA: 0s - loss: 0.6867 - acc: 0.543 - ETA: 0s - loss: 0.6921 - acc: 0.535 - ETA: 0s - loss: 0.6904 - acc: 0.536 - ETA: 0s - loss: 0.6897 - acc: 0.538 - 0s 113us/sample - loss: 0.6914 - acc: 0.5368 - val_loss: 0.6997 - val_acc: 0.5104\n",
      "Epoch 67/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6774 - acc: 0.562 - ETA: 0s - loss: 0.7002 - acc: 0.508 - ETA: 0s - loss: 0.6962 - acc: 0.513 - ETA: 0s - loss: 0.6934 - acc: 0.516 - ETA: 0s - loss: 0.6952 - acc: 0.513 - 0s 110us/sample - loss: 0.6946 - acc: 0.5166 - val_loss: 0.6983 - val_acc: 0.5072\n",
      "Epoch 68/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6877 - acc: 0.562 - ETA: 0s - loss: 0.6890 - acc: 0.538 - ETA: 0s - loss: 0.6904 - acc: 0.531 - ETA: 0s - loss: 0.6891 - acc: 0.535 - ETA: 0s - loss: 0.6876 - acc: 0.541 - 0s 118us/sample - loss: 0.6874 - acc: 0.5399 - val_loss: 0.7039 - val_acc: 0.4928\n",
      "Epoch 69/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6548 - acc: 0.625 - ETA: 0s - loss: 0.7023 - acc: 0.500 - ETA: 0s - loss: 0.6921 - acc: 0.525 - ETA: 0s - loss: 0.6875 - acc: 0.537 - ETA: 0s - loss: 0.6899 - acc: 0.530 - 0s 114us/sample - loss: 0.6912 - acc: 0.5313 - val_loss: 0.7023 - val_acc: 0.5072\n",
      "Epoch 70/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7124 - acc: 0.562 - ETA: 0s - loss: 0.6987 - acc: 0.507 - ETA: 0s - loss: 0.6986 - acc: 0.509 - ETA: 0s - loss: 0.6976 - acc: 0.512 - ETA: 0s - loss: 0.6970 - acc: 0.516 - 0s 116us/sample - loss: 0.6950 - acc: 0.5232 - val_loss: 0.6996 - val_acc: 0.5120\n",
      "Epoch 71/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6880 - acc: 0.562 - ETA: 0s - loss: 0.6992 - acc: 0.511 - ETA: 0s - loss: 0.6965 - acc: 0.529 - ETA: 0s - loss: 0.6947 - acc: 0.532 - ETA: 0s - loss: 0.6950 - acc: 0.529 - 0s 111us/sample - loss: 0.6946 - acc: 0.5302 - val_loss: 0.7045 - val_acc: 0.5008\n",
      "Epoch 72/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7046 - acc: 0.531 - ETA: 0s - loss: 0.6930 - acc: 0.537 - ETA: 0s - loss: 0.6849 - acc: 0.562 - ETA: 0s - loss: 0.6877 - acc: 0.556 - ETA: 0s - loss: 0.6870 - acc: 0.560 - ETA: 0s - loss: 0.6888 - acc: 0.550 - 0s 126us/sample - loss: 0.6901 - acc: 0.5430 - val_loss: 0.6947 - val_acc: 0.5233\n",
      "Epoch 73/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6911 - acc: 0.531 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6914 - acc: 0.528 - ETA: 0s - loss: 0.6912 - acc: 0.530 - ETA: 0s - loss: 0.6928 - acc: 0.528 - 0s 113us/sample - loss: 0.6926 - acc: 0.5290 - val_loss: 0.6980 - val_acc: 0.5169\n",
      "Epoch 74/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6652 - acc: 0.500 - ETA: 0s - loss: 0.6880 - acc: 0.553 - ETA: 0s - loss: 0.6889 - acc: 0.543 - ETA: 0s - loss: 0.6919 - acc: 0.531 - ETA: 0s - loss: 0.6902 - acc: 0.533 - 0s 117us/sample - loss: 0.6919 - acc: 0.5310 - val_loss: 0.6939 - val_acc: 0.5265\n",
      "Epoch 75/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6870 - acc: 0.500 - ETA: 0s - loss: 0.6971 - acc: 0.508 - ETA: 0s - loss: 0.6943 - acc: 0.514 - ETA: 0s - loss: 0.6948 - acc: 0.512 - ETA: 0s - loss: 0.6924 - acc: 0.523 - 0s 114us/sample - loss: 0.6923 - acc: 0.5283 - val_loss: 0.6961 - val_acc: 0.5217\n",
      "Epoch 76/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.562 - ETA: 0s - loss: 0.6938 - acc: 0.516 - ETA: 0s - loss: 0.6916 - acc: 0.534 - ETA: 0s - loss: 0.6916 - acc: 0.532 - ETA: 0s - loss: 0.6912 - acc: 0.526 - 0s 112us/sample - loss: 0.6912 - acc: 0.5290 - val_loss: 0.6971 - val_acc: 0.5201\n",
      "Epoch 77/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6759 - acc: 0.593 - ETA: 0s - loss: 0.6864 - acc: 0.531 - ETA: 0s - loss: 0.6927 - acc: 0.521 - ETA: 0s - loss: 0.6902 - acc: 0.526 - ETA: 0s - loss: 0.6892 - acc: 0.533 - 0s 111us/sample - loss: 0.6908 - acc: 0.5341 - val_loss: 0.6982 - val_acc: 0.5185\n",
      "Epoch 78/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7098 - acc: 0.562 - ETA: 0s - loss: 0.6910 - acc: 0.541 - ETA: 0s - loss: 0.6863 - acc: 0.545 - ETA: 0s - loss: 0.6859 - acc: 0.545 - ETA: 0s - loss: 0.6885 - acc: 0.540 - 0s 114us/sample - loss: 0.6909 - acc: 0.5395 - val_loss: 0.7041 - val_acc: 0.4976\n",
      "Epoch 79/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7698 - acc: 0.343 - ETA: 0s - loss: 0.7050 - acc: 0.502 - ETA: 0s - loss: 0.6995 - acc: 0.507 - ETA: 0s - loss: 0.6960 - acc: 0.510 - ETA: 0s - loss: 0.6945 - acc: 0.520 - 0s 115us/sample - loss: 0.6942 - acc: 0.5244 - val_loss: 0.6934 - val_acc: 0.5056\n",
      "Epoch 80/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6784 - acc: 0.562 - ETA: 0s - loss: 0.6923 - acc: 0.534 - ETA: 0s - loss: 0.6909 - acc: 0.535 - ETA: 0s - loss: 0.6897 - acc: 0.531 - ETA: 0s - loss: 0.6910 - acc: 0.531 - 0s 111us/sample - loss: 0.6899 - acc: 0.5344 - val_loss: 0.7007 - val_acc: 0.4944\n",
      "Epoch 81/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7229 - acc: 0.437 - ETA: 0s - loss: 0.6841 - acc: 0.562 - ETA: 0s - loss: 0.6919 - acc: 0.541 - ETA: 0s - loss: 0.6938 - acc: 0.542 - ETA: 0s - loss: 0.6918 - acc: 0.547 - 0s 111us/sample - loss: 0.6898 - acc: 0.5515 - val_loss: 0.7168 - val_acc: 0.4944\n",
      "Epoch 82/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6694 - acc: 0.562 - ETA: 0s - loss: 0.7002 - acc: 0.491 - ETA: 0s - loss: 0.6944 - acc: 0.512 - ETA: 0s - loss: 0.6954 - acc: 0.512 - ETA: 0s - loss: 0.6909 - acc: 0.525 - 0s 118us/sample - loss: 0.6914 - acc: 0.5271 - val_loss: 0.6985 - val_acc: 0.5104\n",
      "Epoch 83/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6873 - acc: 0.562 - ETA: 0s - loss: 0.6950 - acc: 0.503 - ETA: 0s - loss: 0.6938 - acc: 0.522 - ETA: 0s - loss: 0.6915 - acc: 0.535 - ETA: 0s - loss: 0.6908 - acc: 0.537 - 0s 116us/sample - loss: 0.6908 - acc: 0.5395 - val_loss: 0.7102 - val_acc: 0.5104\n",
      "Epoch 84/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6886 - acc: 0.562 - ETA: 0s - loss: 0.6835 - acc: 0.557 - ETA: 0s - loss: 0.6886 - acc: 0.546 - ETA: 0s - loss: 0.6900 - acc: 0.542 - ETA: 0s - loss: 0.6913 - acc: 0.540 - 0s 109us/sample - loss: 0.6911 - acc: 0.5402 - val_loss: 0.6942 - val_acc: 0.5217\n",
      "Epoch 85/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6711 - acc: 0.656 - ETA: 0s - loss: 0.6860 - acc: 0.560 - ETA: 0s - loss: 0.6853 - acc: 0.554 - ETA: 0s - loss: 0.6869 - acc: 0.548 - ETA: 0s - loss: 0.6913 - acc: 0.535 - 0s 108us/sample - loss: 0.6916 - acc: 0.5344 - val_loss: 0.6948 - val_acc: 0.5072\n",
      "Epoch 86/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6955 - acc: 0.437 - ETA: 0s - loss: 0.6928 - acc: 0.537 - ETA: 0s - loss: 0.6915 - acc: 0.530 - ETA: 0s - loss: 0.6939 - acc: 0.517 - ETA: 0s - loss: 0.6925 - acc: 0.526 - 0s 116us/sample - loss: 0.6905 - acc: 0.5387 - val_loss: 0.7046 - val_acc: 0.5072\n",
      "Epoch 87/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6727 - acc: 0.500 - ETA: 0s - loss: 0.6789 - acc: 0.560 - ETA: 0s - loss: 0.6840 - acc: 0.551 - ETA: 0s - loss: 0.6837 - acc: 0.551 - ETA: 0s - loss: 0.6849 - acc: 0.552 - 0s 112us/sample - loss: 0.6863 - acc: 0.5507 - val_loss: 0.7052 - val_acc: 0.5056\n",
      "Epoch 88/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6580 - acc: 0.625 - ETA: 0s - loss: 0.6815 - acc: 0.564 - ETA: 0s - loss: 0.6890 - acc: 0.549 - ETA: 0s - loss: 0.6899 - acc: 0.552 - ETA: 0s - loss: 0.6903 - acc: 0.550 - 0s 113us/sample - loss: 0.6894 - acc: 0.5526 - val_loss: 0.6991 - val_acc: 0.5088\n",
      "Epoch 89/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7102 - acc: 0.500 - ETA: 0s - loss: 0.6959 - acc: 0.534 - ETA: 0s - loss: 0.6919 - acc: 0.542 - ETA: 0s - loss: 0.6916 - acc: 0.546 - ETA: 0s - loss: 0.6921 - acc: 0.540 - 0s 115us/sample - loss: 0.6926 - acc: 0.5391 - val_loss: 0.6981 - val_acc: 0.4848\n",
      "Epoch 90/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6624 - acc: 0.625 - ETA: 0s - loss: 0.6790 - acc: 0.564 - ETA: 0s - loss: 0.6838 - acc: 0.557 - ETA: 0s - loss: 0.6831 - acc: 0.557 - ETA: 0s - loss: 0.6848 - acc: 0.550 - 0s 112us/sample - loss: 0.6844 - acc: 0.5515 - val_loss: 0.7105 - val_acc: 0.5024\n",
      "Epoch 91/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6514 - acc: 0.625 - ETA: 0s - loss: 0.6879 - acc: 0.555 - ETA: 0s - loss: 0.6915 - acc: 0.541 - ETA: 0s - loss: 0.6914 - acc: 0.544 - ETA: 0s - loss: 0.6896 - acc: 0.545 - 0s 112us/sample - loss: 0.6905 - acc: 0.5441 - val_loss: 0.6981 - val_acc: 0.5008\n",
      "Epoch 92/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6838 - acc: 0.531 - ETA: 0s - loss: 0.6883 - acc: 0.564 - ETA: 0s - loss: 0.6877 - acc: 0.552 - ETA: 0s - loss: 0.6874 - acc: 0.549 - ETA: 0s - loss: 0.6893 - acc: 0.547 - 0s 114us/sample - loss: 0.6896 - acc: 0.5461 - val_loss: 0.7018 - val_acc: 0.5201\n",
      "Epoch 93/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6822 - acc: 0.562 - ETA: 0s - loss: 0.6887 - acc: 0.550 - ETA: 0s - loss: 0.6865 - acc: 0.550 - ETA: 0s - loss: 0.6846 - acc: 0.552 - ETA: 0s - loss: 0.6840 - acc: 0.554 - 0s 114us/sample - loss: 0.6846 - acc: 0.5546 - val_loss: 0.7093 - val_acc: 0.5169\n",
      "Epoch 94/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7013 - acc: 0.406 - ETA: 0s - loss: 0.6969 - acc: 0.517 - ETA: 0s - loss: 0.6902 - acc: 0.544 - ETA: 0s - loss: 0.6914 - acc: 0.535 - ETA: 0s - loss: 0.6923 - acc: 0.534 - 0s 118us/sample - loss: 0.6911 - acc: 0.5368 - val_loss: 0.7016 - val_acc: 0.5136\n",
      "Epoch 95/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7081 - acc: 0.468 - ETA: 0s - loss: 0.6936 - acc: 0.520 - ETA: 0s - loss: 0.6932 - acc: 0.529 - ETA: 0s - loss: 0.6943 - acc: 0.533 - ETA: 0s - loss: 0.6940 - acc: 0.527 - 0s 118us/sample - loss: 0.6913 - acc: 0.5344 - val_loss: 0.6995 - val_acc: 0.5169\n",
      "Epoch 96/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.7021 - acc: 0.562 - ETA: 0s - loss: 0.6848 - acc: 0.552 - ETA: 0s - loss: 0.6843 - acc: 0.557 - ETA: 0s - loss: 0.6908 - acc: 0.539 - ETA: 0s - loss: 0.6906 - acc: 0.538 - 0s 117us/sample - loss: 0.6905 - acc: 0.5375 - val_loss: 0.7001 - val_acc: 0.5152\n",
      "Epoch 97/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6146 - acc: 0.718 - ETA: 0s - loss: 0.6850 - acc: 0.547 - ETA: 0s - loss: 0.6850 - acc: 0.565 - ETA: 0s - loss: 0.6899 - acc: 0.545 - ETA: 0s - loss: 0.6905 - acc: 0.535 - 0s 113us/sample - loss: 0.6898 - acc: 0.5406 - val_loss: 0.6994 - val_acc: 0.5008\n",
      "Epoch 98/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6874 - acc: 0.593 - ETA: 0s - loss: 0.6794 - acc: 0.550 - ETA: 0s - loss: 0.6890 - acc: 0.531 - ETA: 0s - loss: 0.6886 - acc: 0.534 - ETA: 0s - loss: 0.6886 - acc: 0.544 - 0s 113us/sample - loss: 0.6895 - acc: 0.5441 - val_loss: 0.7144 - val_acc: 0.4912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6801 - acc: 0.593 - ETA: 0s - loss: 0.6867 - acc: 0.552 - ETA: 0s - loss: 0.6855 - acc: 0.554 - ETA: 0s - loss: 0.6851 - acc: 0.556 - ETA: 0s - loss: 0.6872 - acc: 0.551 - 0s 112us/sample - loss: 0.6874 - acc: 0.5499 - val_loss: 0.7021 - val_acc: 0.5169\n",
      "Epoch 100/100\n",
      "2584/2584 [==============================] - ETA: 0s - loss: 0.6803 - acc: 0.656 - ETA: 0s - loss: 0.6902 - acc: 0.523 - ETA: 0s - loss: 0.6900 - acc: 0.525 - ETA: 0s - loss: 0.6898 - acc: 0.524 - ETA: 0s - loss: 0.6865 - acc: 0.537 - 0s 112us/sample - loss: 0.6878 - acc: 0.5348 - val_loss: 0.7045 - val_acc: 0.4944\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_tr, y_train, validation_data=(X_test_tr, y_test), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history[\"loss\"])\n",
    "plt.plot(hist.history[\"val_loss\"])\n",
    "plt.legend([\"loss\",\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_binary = np.where(predictions > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/623 [==============================] - ETA: 0s - loss: 0.7291 - acc: 0.312 - 0s 85us/sample - loss: 0.7045 - acc: 0.4944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7045035697101207, 0.49438202]"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_tr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-95ac8050aeb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_tr)\n",
    "plt.plot(predictions.flatten())\n",
    "plt.plot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_4 (Bidirection (None, None, 400)         1550400   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, None, 400)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, None, 50)          20050     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, None, 1)           51        \n",
      "=================================================================\n",
      "Total params: 1,570,501\n",
      "Trainable params: 1,570,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the LSTM model\n",
    "n_steps = 120\n",
    "n_features = 768\n",
    "model = Sequential()\n",
    "#model.add(CuDNNLSTM(200, input_shape=(None, n_features), return_sequences= True))\n",
    "model.add(Input((None, n_features)))\n",
    "model.add(Bidirectional(LSTM(200, return_sequences = True)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(TimeDistributed(Dense(50, activation='relu')))\n",
    "model.add(Dense(1, activation='elu'))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 200)               153800    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 194,201\n",
      "Trainable params: 194,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the Dense Model\n",
    "\n",
    "n_features = 768\n",
    "model = Sequential()\n",
    "model.add(Input(n_features))\n",
    "model.add(Dense(200, activation='elu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(200, activation='elu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics = [\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(max_seq_length):\n",
    "    # Build model\n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "    input_masks = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "    input_segments = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    bert_inputs = [input_word_ids, input_masks, input_segments]\n",
    "    \n",
    "\n",
    "    \n",
    "    albert_model = TFAlbertModel.from_pretrained(\"albert-base-v1\")\n",
    "    sequence_output, pooled_output = albert_model([input_word_ids, input_masks, input_segments])\n",
    "    \n",
    "    #Build LSTM layer\n",
    "    lstm = tf.keras.layers.LSTM(200, dropout=0.1, recurrent_dropout=0.1)(sequence_output)\n",
    "\n",
    "    # Build the rest of the classifier \n",
    "    dense = tf.keras.layers.Dense(max_seq_length, activation='relu')(pooled_output)\n",
    "    #dense = tf.keras.layers.Dense(max_seq_length, activation='relu')(dense)\n",
    "    pred = tf.keras.layers.Dense(2, activation = 'sigmoid', name = \"output\")(dense)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_own_pad_sequence(array, maxlen):\n",
    "    X_tr = []\n",
    "    for x in array:\n",
    "        length =  x.shape[0]\n",
    "        if length > maxlen:\n",
    "            X_tr.append(x[:maxlen])\n",
    "        else:\n",
    "            pad_diff = maxlen - length\n",
    "            x = np.vstack((x, np.zeros([pad_diff,x.shape[1]])))\n",
    "            X_tr.append(x)\n",
    "    return np.array(X_tr)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y for one sequence per day\n",
    "maxlen = 3000\n",
    "X_train_tr = my_own_pad_sequence(train_bert_concat_articles, maxlen)\n",
    "X_test_tr = my_own_pad_sequence(test_bert_concat_articles, maxlen)\n",
    "y_train = train_labels\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAFTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_labels = df_diff[\"BTC-USD\"].loc[:\"2019-12-31\"]\n",
    "test_labels = df_diff[\"BTC-USD\"].loc[\"2020-01-01\":]\n",
    "train_labels = train_labels[pd.DatetimeIndex(train_sentences.groupby(train_sentences.index).count().index)]\n",
    "test_labels = test_labels[pd.DatetimeIndex(test_sentences.groupby(test_sentences.index).count().index)]\n",
    "assert test_labels.shape == test_bert_concat_articles.shape\n",
    "assert train_labels.shape == train_bert_concat_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 80, 40, 20, 4)"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.arange(10000).reshape(100,5,2,2,5)\n",
    "d.strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array([])   \n",
    "for i in range(0,10):\n",
    "    result = np.append(result, np.array([i]*5))\n",
    "result = result.reshape(10,5)\n",
    "rolling_window_bert_2nd_dim(result,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_bert_2nd_dim(a, window):\n",
    "    shape = (a.shape[0] - window + 1, window, a.shape[1])\n",
    "    strides = (a.strides[0], a.strides[1]*a.shape[1], a.strides[1])\n",
    "    #print(shape, strides)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#window = 100\n",
    "#X_train = [rolling_window_bert_2nd_dim(element, window) for element in train_bert_concat_articles]\n",
    "#X_test = [rolling_window_bert_2nd_dim(element, window) for element in test_bert_concat_articles]\n",
    "#y_train = train_labels\n",
    "#y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_train_tr= pad_sequences(train_bert_concat_articles, maxlen=maxlen, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tr = my_own_pad_sequence(train_bert_concat_articles, maxlen)\n",
    "X_test_tr = my_own_pad_sequence(test_bert_concat_articles, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 5000\n",
    "X_train_tr= pad_sequences(X_train, maxlen=maxlen, truncating='post')\n",
    "X_test_tr= pad_sequences(X_test, maxlen=maxlen, truncating='post')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  5.,  46., 104., 109.,  50.,  22.,  19.,   5.,   1.,   1.,   1.,\n",
       "          0.,   0.,   0.,   1.]),\n",
       " array([ 1478.        ,  2177.26666667,  2876.53333333,  3575.8       ,\n",
       "         4275.06666667,  4974.33333333,  5673.6       ,  6372.86666667,\n",
       "         7072.13333333,  7771.4       ,  8470.66666667,  9169.93333333,\n",
       "         9869.2       , 10568.46666667, 11267.73333333, 11967.        ]),\n",
       " <a list of 15 Patch objects>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lengths, bins = 15,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
